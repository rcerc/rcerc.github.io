(self.webpackChunkrcerc_github_io=self.webpackChunkrcerc_github_io||[]).push([[517],{5517:(Be,te,R)=>{"use strict";R.r(te),R.d(te,{ROUTES:()=>Oe});var ne=R(467),e=R(4438);let xe=(()=>{class d{el;constructor(r){this.el=r}ngAfterContentInit(){this.enterState()}toggleFullscreen(){var r=this;return(0,ne.A)(function*(){null===document.fullscreenElement?(yield r.el.nativeElement.requestFullscreen(),r.exitState()):(yield document.exitFullscreen(),r.enterState())})()}enterState(){this.el.nativeElement.style.cursor="zoom-in",this.el.nativeElement.title="Click to enter fullscreen"}exitState(){this.el.nativeElement.style.cursor="zoom-out",this.el.nativeElement.title="Click to exit fullscreen"}static \u0275fac=function(u){return new(u||d)(e.rXU(e.aKT))};static \u0275dir=e.FsC({type:d,selectors:[["","appFullscreen",""]],hostBindings:function(u,j){1&u&&e.bIt("click",function(){return j.toggleFullscreen()})},standalone:!0})}return d})();const se=R(6653);var z=R(177),le=R(6354),W=R(1626);let ce=(()=>{class d{http;cells;constructor(r){this.http=r,this.cells=this.http.get("assets/posts/classifying-text-with-neural-networks/notebook.ipynb").pipe((0,le.T)(({cells:u})=>u))}requestCell(r){return this.cells.pipe((0,le.T)(u=>u[r]))}static \u0275fac=function(u){return new(u||d)(e.KVO(W.Qq))};static \u0275prov=e.jDH({token:d,factory:d.\u0275fac,providedIn:"root"})}return d})();const Fe=["hljs"],ve=["wrapper"],B=["*"];function Ee(d,T){if(1&d&&(e.j41(0,"pre")(1,"code"),e.EFF(2),e.k0s()()),2&d){const r=T.$implicit;e.R7$(2),e.JRh(r)}}function ie(d,T){if(1&d&&(e.j41(0,"div"),e.EFF(1," Output: "),e.DNE(2,Ee,3,1,"pre",4),e.k0s()),2&d){const r=e.XpG();e.R7$(2),e.Y8G("ngForOf",r.outputs)}}se.registerLanguage("python",function _e(d){const T=d.regex,r=new RegExp("[\\p{XID_Start}_]\\p{XID_Continue}*","u"),u=["and","as","assert","async","await","break","case","class","continue","def","del","elif","else","except","finally","for","from","global","if","import","in","is","lambda","match","nonlocal|10","not","or","pass","raise","return","try","while","with","yield"],N={$pattern:/[A-Za-z]\w+|__\w+__/,keyword:u,built_in:["__import__","abs","all","any","ascii","bin","bool","breakpoint","bytearray","bytes","callable","chr","classmethod","compile","complex","delattr","dict","dir","divmod","enumerate","eval","exec","filter","float","format","frozenset","getattr","globals","hasattr","hash","help","hex","id","input","int","isinstance","issubclass","iter","len","list","locals","map","max","memoryview","min","next","object","oct","open","ord","pow","print","property","range","repr","reversed","round","set","setattr","slice","sorted","staticmethod","str","sum","super","tuple","type","vars","zip"],literal:["__debug__","Ellipsis","False","None","NotImplemented","True"],type:["Any","Callable","Coroutine","Dict","List","Literal","Generic","Optional","Sequence","Set","Tuple","Type","Union"]},L={className:"meta",begin:/^(>>>|\.\.\.) /},V={className:"subst",begin:/\{/,end:/\}/,keywords:N,illegal:/#/},J={begin:/\{\{/,relevance:0},q={className:"string",contains:[d.BACKSLASH_ESCAPE],variants:[{begin:/([uU]|[bB]|[rR]|[bB][rR]|[rR][bB])?'''/,end:/'''/,contains:[d.BACKSLASH_ESCAPE,L],relevance:10},{begin:/([uU]|[bB]|[rR]|[bB][rR]|[rR][bB])?"""/,end:/"""/,contains:[d.BACKSLASH_ESCAPE,L],relevance:10},{begin:/([fF][rR]|[rR][fF]|[fF])'''/,end:/'''/,contains:[d.BACKSLASH_ESCAPE,L,J,V]},{begin:/([fF][rR]|[rR][fF]|[fF])"""/,end:/"""/,contains:[d.BACKSLASH_ESCAPE,L,J,V]},{begin:/([uU]|[rR])'/,end:/'/,relevance:10},{begin:/([uU]|[rR])"/,end:/"/,relevance:10},{begin:/([bB]|[bB][rR]|[rR][bB])'/,end:/'/},{begin:/([bB]|[bB][rR]|[rR][bB])"/,end:/"/},{begin:/([fF][rR]|[rR][fF]|[fF])'/,end:/'/,contains:[d.BACKSLASH_ESCAPE,J,V]},{begin:/([fF][rR]|[rR][fF]|[fF])"/,end:/"/,contains:[d.BACKSLASH_ESCAPE,J,V]},d.APOS_STRING_MODE,d.QUOTE_STRING_MODE]},D="[0-9](_?[0-9])*",de=`(\\b(${D}))?\\.(${D})|\\b(${D})\\.`,U=`\\b|${u.join("|")}`,Q={className:"number",relevance:0,variants:[{begin:`(\\b(${D})|(${de}))[eE][+-]?(${D})[jJ]?(?=${U})`},{begin:`(${de})[jJ]?`},{begin:`\\b([1-9](_?[0-9])*|0+(_?0)*)[lLjJ]?(?=${U})`},{begin:`\\b0[bB](_?[01])+[lL]?(?=${U})`},{begin:`\\b0[oO](_?[0-7])+[lL]?(?=${U})`},{begin:`\\b0[xX](_?[0-9a-fA-F])+[lL]?(?=${U})`},{begin:`\\b(${D})[jJ](?=${U})`}]},Ce={className:"comment",begin:T.lookahead(/# type:/),end:/$/,keywords:N,contains:[{begin:/# type:/},{begin:/#/,end:/\b\B/,endsWithParent:!0}]},ge={className:"params",variants:[{className:"",begin:/\(\s*\)/,skip:!0},{begin:/\(/,end:/\)/,excludeBegin:!0,excludeEnd:!0,keywords:N,contains:["self",L,Q,q,d.HASH_COMMENT_MODE]}]};return V.contains=[q,Q,L],{name:"Python",aliases:["py","gyp","ipython"],unicodeRegex:!0,keywords:N,illegal:/(<\/|\?)|=>/,contains:[L,Q,{begin:/\bself\b/},{beginKeywords:"if",relevance:0},q,Ce,d.HASH_COMMENT_MODE,{match:[/\bdef/,/\s+/,r],scope:{1:"keyword",3:"title.function"},contains:[ge]},{variants:[{match:[/\bclass/,/\s+/,r,/\s*/,/\(\s*/,r,/\s*\)/]},{match:[/\bclass/,/\s+/,r]}],scope:{1:"keyword",3:"title.class",6:"title.class.inherited"}},{className:"meta",begin:/^[\t ]*@/,end:/(?=#)|$/,contains:[Q,ge,q]}]}}),se.registerLanguage("shell",function ae(d){return{name:"Shell Session",aliases:["console","shellsession"],contains:[{className:"meta.prompt",begin:/^\s{0,3}[/~\w\d[\]()@-]*[>%$#][ ]?/,starts:{end:/[^\\](?=\s*$)/,subLanguage:"bash"}}]}});let he=(()=>{class d{nb;pre;content;index;outputs;constructor(r){this.nb=r}ngAfterViewInit(){var r=this;return(0,ne.A)(function*(){const u=r.content?.nativeElement.innerText;if(u)r.highlight(u);else if(void 0!==r.index){const j=yield r.nb.requestCell(r.index).toPromise();if(!j)return void console.error(`cell ${r.index} not found`);const P=j.source.join("");r.highlight(P),r.outputs=j.outputs.map(X=>X.text?.join("")).filter(X=>void 0!==X)}})()}highlight(r){if(void 0!==this.pre){const u=se.highlightAuto(r).value;this.pre.nativeElement.innerHTML=u}}static \u0275fac=function(u){return new(u||d)(e.rXU(ce))};static \u0275cmp=e.VBU({type:d,selectors:[["app-cell"]],viewQuery:function(u,j){if(1&u&&(e.GBs(Fe,5),e.GBs(ve,5)),2&u){let P;e.mGM(P=e.lsd())&&(j.pre=P.first),e.mGM(P=e.lsd())&&(j.content=P.first)}},inputs:{index:"index"},standalone:!0,features:[e.aNF],ngContentSelectors:B,decls:7,vars:1,consts:[["hljs",""],["wrapper",""],[4,"ngIf"],["hidden",""],[4,"ngFor","ngForOf"]],template:function(u,j){1&u&&(e.NAR(),e.j41(0,"pre"),e.nrm(1,"code",null,0),e.k0s(),e.DNE(3,ie,3,1,"div",2),e.j41(4,"div",3,1),e.SdG(6),e.k0s()),2&u&&(e.R7$(3),e.Y8G("ngIf",null==j.outputs?null:j.outputs.length))},dependencies:[z.bT,z.pM],styles:["pre[_ngcontent-%COMP%]   code.hljs[_ngcontent-%COMP%], pre[_ngcontent-%COMP%]   [_ngcontent-%COMP%]:not(pre) > code[_ngcontent-%COMP%], pre[_ngcontent-%COMP%]   code.block[_ngcontent-%COMP%], pre[_ngcontent-%COMP%] > code[_ngcontent-%COMP%]{display:block;overflow-x:auto;padding:1em}code.hljs[_ngcontent-%COMP%], [_ngcontent-%COMP%]:not(pre) > code[_ngcontent-%COMP%], code.block[_ngcontent-%COMP%], pre[_ngcontent-%COMP%] > code[_ngcontent-%COMP%]{padding:3px 5px}\n\n\n\n\n\n\n\n\n\n.hljs[_ngcontent-%COMP%], [_ngcontent-%COMP%]:not(pre) > code[_ngcontent-%COMP%], .block[_ngcontent-%COMP%], pre[_ngcontent-%COMP%] > code[_ngcontent-%COMP%]{color:#c9d1d9;background:#0d1117}.hljs-doctag[_ngcontent-%COMP%], .hljs-keyword[_ngcontent-%COMP%], .hljs-meta[_ngcontent-%COMP%]   .hljs-keyword[_ngcontent-%COMP%], .hljs-template-tag[_ngcontent-%COMP%], .hljs-template-variable[_ngcontent-%COMP%], .hljs-type[_ngcontent-%COMP%], .hljs-variable.language_[_ngcontent-%COMP%]{color:#ff7b72}.hljs-title[_ngcontent-%COMP%], .hljs-title.class_[_ngcontent-%COMP%], .hljs-title.class_.inherited__[_ngcontent-%COMP%], .hljs-title.function_[_ngcontent-%COMP%]{color:#d2a8ff}.hljs-attr[_ngcontent-%COMP%], .hljs-attribute[_ngcontent-%COMP%], .hljs-literal[_ngcontent-%COMP%], .hljs-meta[_ngcontent-%COMP%], .hljs-number[_ngcontent-%COMP%], .hljs-operator[_ngcontent-%COMP%], .hljs-variable[_ngcontent-%COMP%], .hljs-selector-attr[_ngcontent-%COMP%], .hljs-selector-class[_ngcontent-%COMP%], .hljs-selector-id[_ngcontent-%COMP%]{color:#79c0ff}.hljs-regexp[_ngcontent-%COMP%], .hljs-string[_ngcontent-%COMP%], .hljs-meta[_ngcontent-%COMP%]   .hljs-string[_ngcontent-%COMP%]{color:#a5d6ff}.hljs-built_in[_ngcontent-%COMP%], .hljs-symbol[_ngcontent-%COMP%]{color:#ffa657}.hljs-comment[_ngcontent-%COMP%], .hljs-code[_ngcontent-%COMP%], .hljs-formula[_ngcontent-%COMP%]{color:#8b949e}.hljs-name[_ngcontent-%COMP%], .hljs-quote[_ngcontent-%COMP%], .hljs-selector-tag[_ngcontent-%COMP%], .hljs-selector-pseudo[_ngcontent-%COMP%]{color:#7ee787}.hljs-subst[_ngcontent-%COMP%]{color:#c9d1d9}.hljs-section[_ngcontent-%COMP%]{color:#1f6feb;font-weight:700}.hljs-bullet[_ngcontent-%COMP%]{color:#f2cc60}.hljs-emphasis[_ngcontent-%COMP%]{color:#c9d1d9;font-style:italic}.hljs-strong[_ngcontent-%COMP%]{color:#c9d1d9;font-weight:700}.hljs-addition[_ngcontent-%COMP%]{color:#aff5b4;background-color:#033a16}.hljs-deletion[_ngcontent-%COMP%]{color:#ffdcd7;background-color:#67060c}.block[_ngcontent-%COMP%], pre[_ngcontent-%COMP%] > code[_ngcontent-%COMP%]{border-radius:4px;font-family:inherit;padding:12px 16px;overflow-x:auto;text-align:left}.snippet[_ngcontent-%COMP%], [_ngcontent-%COMP%]:not(pre) > code[_ngcontent-%COMP%]{font-family:inherit;border-radius:2px;line-height:1.6em;padding:3px 4px}pre[_ngcontent-%COMP%]{font-family:inherit}"]})}return d})();var je=R(345);function Me(d,T){if(1&d&&(e.qSk(),e.j41(0,"g"),e.nrm(1,"circle",253)(2,"circle",254)(3,"circle",253)(4,"circle",254),e.k0s()),2&d){const r=T.$implicit,u=e.XpG();e.R7$(),e.BMQ("cx",8*r)("cy",-32*u.sigmoid(r/2-u.xValues.length/4)),e.R7$(),e.BMQ("cx",8*r)("cy",-32*u.sigmoid_prime(r/2-u.xValues.length/4)),e.R7$(),e.BMQ("cx",8+8*(r+u.xValues.length))("cy",-32*u.tanh(r/2-u.xValues.length/4)),e.R7$(),e.BMQ("cx",8+8*(r+u.xValues.length))("cy",-32*u.tanh_prime(r/2-u.xValues.length/4))}}const Oe=[{path:"",component:(()=>{class d{xValues=Array(32).fill(0).map((r,u)=>u);constructor(r){r.setTitle("Classifying Text With Neural Networks")}ngAfterViewInit(){const r=document.createElement("script");r.src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js",document.head.appendChild(r)}sigmoid(r){return 1/(1+Math.exp(-r))}sigmoid_prime(r){const u=this.sigmoid(r);return u*(1-u)}tanh(r){return Math.tanh(r)}tanh_prime(r){return 1/Math.cosh(r)**2}ln(r){return Math.log(r)}ln_prime(r){return 1/r}static \u0275fac=function(u){return new(u||d)(e.rXU(je.hE))};static \u0275cmp=e.VBU({type:d,selectors:[["app-classifying-text-with-neural-networks"]],standalone:!0,features:[e.aNF],decls:784,vars:40,consts:[["xmlns","http://www.w3.org/2000/svg",2,"position","absolute"],["id","diode","orient","auto","markerWidth","13","markerHeight","4","refX","12","refY","2"],["points","0,0 0,4 4,2"],["id","head","orient","auto","markerWidth","13","markerHeight","4","refX","12","refY","2"],["x1","1","y1","2","x2","13","y2","2","stroke-width","3",2,"stroke","linen"],["id","ellipsis"],["href","#empty"],["text-anchor","middle","dominant-baseline","middle"],["id","dot","r","16"],["id","el-sum"],["href","#dot"],["x1","-8","x2","8",2,"stroke","linen"],["y1","-8","y2","8",2,"stroke","linen"],["id","el-prod"],["r","2","fill","linen"],["r","12","fill","none","stroke","linen","stroke-width","2"],["id","layer","x","-16","y","-16","width","32","height","32"],["id","cell"],["x","-16","y","-16","width","32","height","32","rx","8"],["text-anchor","middle","dominant-baseline","middle","fill","linen","font-size","12px"],["id","empty","href","#layer","fill","linen"],["id","intersection","x","-8","y","-8","width","16","height","16","fill","linen"],["id","sigmoid","fill","linen","text-anchor","middle","dominant-baseline","middle",2,"font-size","24px"],["id","tanh","fill","linen","text-anchor","middle","dominant-baseline","middle",2,"font-size","12px"],["id","one-minus","fill","linen","text-anchor","middle","dominant-baseline","middle",2,"font-size","18px"],["id","el-sigmoid"],["href","#sigmoid"],["id","el-tanh"],["href","#tanh"],["id","el-one-minus"],["href","#one-minus"],["id","layer-sigmoid"],["href","#layer"],["id","layer-tanh"],["id","column"],["id","title"],["href","https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"],["href","https://www.youtube.com/playlist?list=PLxt59R_fWVzT9bDxA76AHm3ig0Gg9S3So"],["xmlns","http://www.w3.org/2000/svg","viewBox","-16 -16 416 224"],["id","segment"],["x1","64","y1","64","x2","64",1,"arrow"],["y1","64","x2","128","y2","64",1,"arrow"],["y1","128","y2","64",1,"arrow"],["href","#cell","y","64"],["href","#empty","y","128"],["text-anchor","middle","dominant-baseline","middle","x","64"],["text-anchor","middle","dominant-baseline","middle","y","128"],["href","#segment"],["href","#segment","x","128"],["href","#segment","x","256"],["href","#ellipsis","x","384","y","64"],["y1","192","x2","416","y2","192",1,"arrow"],["text-anchor","middle","x","192","y","190"],["xmlns","http://www.w3.org/2000/svg","height","120","viewBox","0 0 158 90"],["transform","translate(20, 16)"],["x2","64",1,"arrow"],["x1","64","x2","128",1,"arrow"],["x","64","href","#layer-sigmoid"],["x","-20","y","-10","width","40","height","20","fill","linen"],["x","-20","y","-10","width","40","height","22"],["x","118","y","-10","width","20","height","22"],["x","54","y","55","width","20","height","18","fill","linen"],["x","54","y","55","width","20","height","18"],["xmlns","http://www.w3.org/2000/svg","viewBox","-16 -16 288 160"],["x1","64","y1","128","y2","128",1,"arrow"],["href","#ellipsis"],["href","#ellipsis","y","128"],["transform","translate(64)"],["x1","128","x2","192",1,"arrow"],["x1","128","y1","128","x2","64","y2","128",1,"arrow"],["x1","192","y1","128","x2","128","y2","128",1,"arrow"],["y1","64",1,"arrow"],["y1","64","y2","128",1,"arrow"],["x1","128","y1","64","x2","128","y2","128",1,"arrow"],["x1","128","y1","64","x2","128",1,"arrow"],["href","#cell"],["href","#ellipsis","x","64"],["href","#ellipsis","x","192"],["href","#cell","x","128"],["href","#cell","y","128"],["href","#ellipsis","x","64","y","128"],["href","#ellipsis","x","192","y","128"],["href","#cell","x","128","y","128"],["href","#dependent"],["href","#dependent","y","128"],["href","#empty","y","64"],["href","#empty","x","128","y","64"],["transform","translate(0, 64)","font-size","8px"],["x","-16","dominant-baseline","middle"],["x","64","text-anchor","middle","dominant-baseline","middle","font-style","italic"],["x","128","text-anchor","middle","dominant-baseline","middle"],["x","192","text-anchor","middle","dominant-baseline","middle","font-style","italic"],["x","272","text-anchor","end","dominant-baseline","middle"],["xmlns","http://www.w3.org/2000/svg","viewBox","-2 -64 516 128"],["y","-10","font-size","12px"],["y1","-8","x2","248","y2","-8","stroke-dasharray","4",2,"opacity","0.2"],["x2","248"],["x1","128","y1","-50%","x2","128","y2","50%"],["x","264","y","-34","font-size","12px"],["x1","264","y1","-32","x2","100%","y2","-32","stroke-dasharray","4",2,"opacity","0.2"],["x1","264","x2","100%"],["x1","392","y1","-50%","x2","392","y2","50%"],["y","50%","font-size","12px","dominant-baseline","ideographic"],["x","50%","y","50%","font-size","12px","text-anchor","middle","dominant-baseline","ideographic","fill","crimson"],["x","512","y","50%","font-size","12px","text-anchor","end","dominant-baseline","ideographic"],[4,"ngFor","ngForOf"],["href","https://www.researchgate.net/publication/13853244_Long_Short-term_Memory"],["xmlns","http://www.w3.org/2000/svg","viewBox","-16 -16 416 288"],["id","lstm-forget-input-can-output"],["y1","192","x2","64","y2","192"],["x1","64","y1","256","x2","64","y2","192"],["x","-20.5","y","180.5","width","41","height","23"],[2,"background-color","linen"],["x","46.5","y","241.5","width","35","height","29"],["id","lstm-input-can-output"],["x1","64","y1","192","x2","128","y2","192"],["id","lstm-input-state"],["points","128,128 128,64 192,64",1,"arrow"],["href","#layer-sigmoid","x","128","y","128"],["id","lstm-can-state"],["x1","192","y1","128","x2","192","y2","64",1,"arrow"],["href","#layer-tanh","x","192","y","128"],["id","lstm-input"],["x1","128","y1","192","x2","128","y2","128",1,"arrow"],["id","lstm-can"],["x1","192","y1","192","x2","192","y2","128",1,"arrow"],["id","lstm-rel"],["x1","320","x2","320","y2","64",1,"arrow"],["x1","320","y1","64","x2","320","y2","192",1,"arrow"],["href","#el-tanh","x","320","y","64"],["x1","320","y1","192","x2","384","y2","192",1,"arrow"],["href","#el-prod","x","320","y","192"],["x","372.5","y","180","width","23","height","24"],["id","lstm-state-rel"],["x1","192","x2","320"],["href","#el-sum","x","192"],["id","lstm-state"],["x","-20.5","y","-11.5","width","41","height","23"],["x1","64","x2","192",1,"arrow"],["href","#el-prod","x","64"],["x1","192","y1","64","x2","192",1,"arrow"],["href","#el-prod","x","192","y","64"],["x1","320","x2","384",1,"arrow"],["x","372.5","y","-10","width","23","height","20"],["id","lstm-can-output"],["x1","128","y1","192","x2","192","y2","192"],["id","lstm-output-rel"],["x1","256","y1","192","x2","320","y2","192",1,"arrow"],["href","#layer-sigmoid","x","256","y","192"],["id","lstm-forget-state"],["x1","64","y1","128","x2","64",1,"arrow"],["href","#layer-sigmoid","x","64","y","128"],["id","lstm-forget"],["x1","64","y1","192","x2","64","y2","128",1,"arrow"],["id","lstm-output"],["x1","192","y1","192","x2","256","y2","192"],["href","#lstm-forget-input-can-output"],["href","#lstm-input"],["href","#lstm-input-state"],["href","#lstm-can"],["href","#lstm-can-state"],["href","#lstm-input-can-output"],["href","#lstm-can-output"],["href","#lstm-output"],["href","#lstm-output-rel"],["href","#lstm-rel"],["href","#lstm-forget"],["href","#lstm-forget-state"],["href","#lstm-state"],["href","#lstm-state-rel"],["font-size","12px"],["x","48","y","112","transform","rotate(-90, 48, 112)","dominant-baseline","hanging"],["x","112","y","112","transform","rotate(-90, 112, 112)","dominant-baseline","hanging"],["x","240","y","176","transform","rotate(-90, 240, 176)","dominant-baseline","hanging"],[2,"opacity","0.2"],["href","https://arxiv.org/abs/1406.1078"],["xmlns","http://www.w3.org/2000/svg","viewBox","-16 -16 480 288"],["id","gru-reset-can-update"],[2,"background-color","linen","padding","2px 0"],["id","gru-reset-can-update-out"],["x2","64"],["x","-19","y","-11.5","width","41","height","23"],["id","gru-reset-update"],["x1","64","x2","64","y2","128",1,"diode"],["x1","64","y1","192","x2","64","y2","128",1,"diode"],["x1","64","y1","128","x2","192","y2","128"],["id","gru-reset-can"],["x1","192","y1","64","x2","128","y2","64",1,"arrow"],["href","#layer-sigmoid","x","192","y","64"],["id","gru-reset"],["id","gru-can-out"],["x1","384","y1","192","x2","384","y2","128",1,"arrow"],["x1","64","x2","128"],["href","#layer-tanh","x","384","y","192"],["id","gru-can"],["x1","128","x2","128","y2","64",1,"arrow"],["points","128,64 128,192 384,192",1,"arrow"],["x1","64","y1","192","x2","128","y2","192",1,"diode"],["href","#intersection","x","128","y","128"],["href","#el-prod","x","128","y","64"],["id","gru-update-out"],["x1","320","y1","128","x2","320","y2","64",1,"arrow"],["x1","256","y1","128","x2","384","y2","128",1,"arrow"],["href","#layer-sigmoid","x","256","y","128"],["id","gru-update"],["x1","192","y1","128","x2","256","y2","128",1,"arrow"],["id","gru-out"],["x1","320","y1","64","x2","320",1,"arrow"],["x1","384","y1","192","x2","384",1,"arrow"],["x1","128","x2","320",1,"arrow"],["x1","384","x2","448",1,"arrow"],["href","#el-sum","x","384"],["href","#el-one-minus","x","320","y","64"],["href","#el-prod","x","320"],["href","#el-prod","x","384","y","128"],["x","436.5","y","-12","width","23","height","24"],["href","#gru-update"],["href","#gru-reset"],["href","#gru-reset-can"],["href","#gru-can"],["href","#gru-update-out"],["href","#gru-reset-can-update"],["href","#gru-reset-update"],["href","#gru-reset-can-update-out"],["href","#gru-can-out"],["href","#gru-out"],["x","208","y","80"],["x","272","y","144"],["id","gru-mask-reset-can"],["width","100%","height","100%","fill","white"],["href","#dot","x","128","y","64"],["href","#gru-reset-can","mask","url(#gru-mask-reset-can)"],["id","gru-not-out"],["id","gru-mask-not-out"],["x","-16","y","-16","width","416","height","416","fill","white"],["href","#gru-not-out",2,"filter","brightness(0)"],["href","#gru-not-out",2,"opacity","0.2"],["href","assets/posts/classifying-text-with-neural-networks/notebook.ipynb"],["href","https://colab.research.google.com/github/rcerc/rcerc.github.io/blob/gh-pages/assets/posts/classifying-text-with-neural-networks/notebook.ipynb"],["href","https://docs.python.org/3/library/venv.html"],[3,"index"],["href","https://www.tensorflow.org/datasets/catalog/overview"],["href","http://localhost:6006"],["appFullscreen","","width","100%","src","assets/posts/classifying-text-with-neural-networks/tensorboard.png","alt","TensorBoard showing a loss and an accuracy graph for training and validation data"],["href","https://github.com/rcerc/rcerc.github.io/discussions"],["href","https://en.wikipedia.org/wiki/Recurrent_neural_network"],["href","https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks"],["href","https://en.wikipedia.org/wiki/Vanishing_gradient_problem"],["href","https://colah.github.io/posts/2015-08-Understanding-LSTMs/"],["href","https://en.wikipedia.org/wiki/Gated_recurrent_unit"],["href","https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization"],["href","https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"],["href","https://www.tensorflow.org/text/tutorials/text_classification_rnn"],["r","2"],["r","2","fill","crimson"]],template:function(u,j){1&u&&(e.qSk(),e.j41(0,"svg",0)(1,"defs")(2,"marker",1),e.nrm(3,"polygon",2),e.k0s(),e.j41(4,"marker",3),e.nrm(5,"line",4)(6,"polygon",2),e.k0s(),e.j41(7,"g",5),e.nrm(8,"use",6),e.j41(9,"text",7),e.EFF(10,"\xb7\xb7\xb7"),e.k0s()(),e.nrm(11,"circle",8),e.j41(12,"g",9),e.nrm(13,"use",10)(14,"line",11)(15,"line",12),e.k0s(),e.j41(16,"g",13),e.nrm(17,"use",10)(18,"circle",14)(19,"circle",15),e.k0s(),e.nrm(20,"rect",16),e.j41(21,"g",17),e.nrm(22,"rect",18),e.j41(23,"text",19),e.EFF(24," cell "),e.k0s()(),e.nrm(25,"use",20)(26,"rect",21),e.j41(27,"text",22),e.EFF(28," \u03c3 "),e.k0s(),e.j41(29,"text",23),e.EFF(30," tanh "),e.k0s(),e.j41(31,"text",24),e.EFF(32," 1- "),e.k0s(),e.j41(33,"g",25),e.nrm(34,"use",10)(35,"use",26),e.k0s(),e.j41(36,"g",27),e.nrm(37,"use",10)(38,"use",28),e.k0s(),e.j41(39,"g",29),e.nrm(40,"use",10)(41,"use",30),e.k0s(),e.j41(42,"g",31),e.nrm(43,"use",32)(44,"use",26),e.k0s(),e.j41(45,"g",33),e.nrm(46,"use",32)(47,"use",28),e.k0s()()(),e.joV(),e.j41(48,"div",34)(49,"h1",35),e.EFF(50,"Classifying Text With Neural Networks"),e.k0s(),e.j41(51,"p"),e.EFF(52," You might have heard of recurrent neural networks (RNNs) and the role they play in natural language processing (NLP). This post hopes to introduce RNNs, how they have been used in text analysis, the modifications made to them over time and how to construct an RNN and train it in Python using TensorFlow, a flexible machine learning library. However, this post is far from a serious analysis, and yours truly is equally far from an expert on the subject; only very lightly and informally shall the theory behind these networks be touched. "),e.k0s(),e.j41(53,"p"),e.EFF(54," This post assumes the reader is somewhat familiar with neural networks and related terms, such as weights, biases, neurons and activation functions. If you aren\u2019t sure what these are, suggested are "),e.j41(55,"a",36),e.EFF(56,"3blue1brown\u2019s"),e.k0s(),e.EFF(57," or "),e.j41(58,"a",37),e.EFF(59,"giant_neural_network\u2019s"),e.k0s(),e.EFF(60," neural network courses. "),e.k0s(),e.j41(61,"h2"),e.EFF(62,"The Plot"),e.k0s(),e.j41(63,"p"),e.EFF(64," Alice hosts an online book store. She has a decent amount of regular customers, who usually leave reviews in the form of text and a corresponding numerical rating from one to five on her website. To simplify the review process, Alice would like to automatically give customers a suggestion for the numerical rating based on the review text. Her customers can either choose the suggested ratings, or select their own if they see it fit. "),e.k0s(),e.j41(65,"p"),e.EFF(66," Fortunately, Alice is familiar with neural networks, which, to her, seem to be almost perfect solutions to her troubles. She plans to assign a number to each word in a review, then feed these numbers through a neural network. She believes that once trained, the output could accurately match the rating her average customer might place. "),e.k0s(),e.j41(67,"p"),e.EFF(68," Alice quickly runs into a problem. Some of the book reviews on her site are relatively long. She speculates that she would have to trim certain reviews before feeding them through her network to ensure they fit if she was to use a regular feedforward one. This might lead to the network inaccurately suggesting a rating if the trimmed text contained crucial information to the review. Alice needs a mechanism that can handle variable-length inputs. This is where RNNs come in. "),e.k0s(),e.j41(69,"h2"),e.EFF(70,"Recurrent Neural Networks"),e.k0s(),e.j41(71,"p"),e.EFF(72," An RNN (recurrent neural network) is a series of identical \u2018cells\u2019 (usually a cell is a single network layer, but can also be a complete network), one present at each moment in time (also called a timestep), that are chained together. More specifically, the output of one cell at one point in time is passed to the next cell, in addition to new input. This enables the network to retain and reuse information stored in the connections between cells over time and is "),e.j41(73,"em"),e.EFF(74,"the"),e.k0s(),e.EFF(75," reason RNNs have been and are used in numerous applications, including speech and handwriting recognition, time series prediction, robot control and even music composition! "),e.k0s(),e.qSk(),e.j41(76,"svg",38)(77,"defs")(78,"g",39),e.nrm(79,"line",40)(80,"line",41)(81,"line",42)(82,"use",43)(83,"use",44),e.j41(84,"text",45),e.EFF(85,"out"),e.k0s(),e.j41(86,"text",46),e.EFF(87,"in"),e.k0s()()(),e.nrm(88,"use",47)(89,"use",48)(90,"use",49)(91,"use",50)(92,"line",51),e.j41(93,"text",52),e.EFF(94,"time"),e.k0s()(),e.joV(),e.j41(95,"p"),e.EFF(96),e.k0s(),e.qSk(),e.j41(97,"svg",53)(98,"g",54),e.nrm(99,"line",55)(100,"line",56)(101,"line",40)(102,"use",57)(103,"rect",58),e.j41(104,"foreignObject",59),e.EFF(105),e.k0s(),e.j41(106,"foreignObject",60),e.EFF(107,"\\(h_t\\)"),e.k0s(),e.nrm(108,"rect",61),e.j41(109,"foreignObject",62),e.EFF(110,"\\(x_t\\)"),e.k0s()()(),e.joV(),e.j41(111,"p"),e.EFF(112),e.k0s(),e.EFF(113),e.j41(114,"p"),e.EFF(115," In most cases, NLP included, \\(h_t\\) is simply fed to the next cell. However, in other cases, \\(h_t\\) is kept and processed later in addition to being fed to the next cell. For example, \\(h_t\\) of an RNN that classifies handwritten letters could encode various characteristics of the written letter which are later used to identify it. "),e.k0s(),e.j41(116,"p"),e.EFF(117," Note that since there is no cell (thus no output) at \\(t = 0\\) (simply because the chain of cells begins at timestep 1, \\(U h_0\\) (the output) is omitted from the sum of weighted inputs and biases: "),e.k0s(),e.EFF(118," \\(h_1 = \\sigma(W x_t + b)\\) "),e.j41(119,"p"),e.EFF(120," RNNs are particularly useful when the length of the input varies or might not be known at all! For example, each word in a sentence could be passed as input to the corresponding cell of an RNN, one at a time, no matter the length of the sentence. Afterwards, the final \\(h_t\\) can be given to a feedforward network to process it further and return the desired output, depending on what kind of problem the network was built to solve. "),e.k0s(),e.j41(121,"h3"),e.EFF(122,"Bidirectional RNNs"),e.k0s(),e.j41(123,"p"),e.EFF(124," There are some RNN systems that are composed of two discrete RNNs, which each process the input in reverse directions. An example relating to NLP would be: no matter whether a pronoun precedes or appears after its corresponding noun in a sentence, one of the two RNNs will be able to process the sentence. To do this, a sequence of inputs is fed in its original order to the first RNN, while the second RNN receives the sequence in reverse. Afterwards, both of the final cell states are given to a feedforward network to process further. The intent is that if the sequence contained information that was pertinent at a previous timestep for the first network (a dependency), the second network (which is fed the reverse sequence) would have received the dependency in question "),e.j41(125,"em"),e.EFF(126,"before"),e.k0s(),e.EFF(127," reaching the cell that needed it. This is shown in the diagram below, where the first chain of cells is fed the input forwards and the second is fed the input backwards. Note that the dependency (\u2018Alice\u2019) reaches the first chain after the dependent (\u2018her\u2019), rendered useless because the dependent timestep has passed. On the other hand, the dependency reaches the second chain before the dependent timestep is reached and can be used by the corresponding cell. "),e.k0s(),e.qSk(),e.j41(128,"svg",63),e.nrm(129,"line",55)(130,"line",64)(131,"use",65)(132,"use",66),e.j41(133,"g",67),e.nrm(134,"line",55)(135,"line",56)(136,"line",68)(137,"line",64)(138,"line",69)(139,"line",70)(140,"line",71)(141,"line",72)(142,"line",73)(143,"line",74)(144,"use",75)(145,"use",76)(146,"use",77)(147,"use",78)(148,"use",79)(149,"use",80)(150,"use",81)(151,"use",82)(152,"use",83)(153,"use",84)(154,"use",85)(155,"use",86),e.k0s(),e.j41(156,"g",87)(157,"text",88),e.EFF(158,"After brushing"),e.k0s(),e.j41(159,"text",89),e.EFF(160," her "),e.k0s(),e.j41(161,"text",90),e.EFF(162," teeth, "),e.k0s(),e.j41(163,"text",91),e.EFF(164," Alice "),e.k0s(),e.j41(165,"text",92),e.EFF(166," went to sleep. "),e.k0s()()(),e.joV(),e.j41(167,"h3"),e.EFF(168,"The Vanishing Gradient"),e.k0s(),e.j41(169,"i"),e.EFF(170,"sounds mysterious..."),e.k0s(),e.j41(171,"p"),e.EFF(172," Vanilla RNNs suffer from the vanishing gradient problem, which is an issue that can appear when training many-layer neural networks. The rate of change of the cost function, by the chain rule, takes into account the effect of (1) changing the weights for only the last recurrence, (2) changing the weights for only the second-last recurrence, etc. But, depending on how small the weights and derivatives of the activation functions are, the terms in this list can become increasingly small due to repeated multiplication of numbers with magnitude less than \\(1\\). (For example, sigmoid and tanh (hyperbolic tangent) have derivatives that are positive and less than or equal to 0.25 and 1, respectively.) Hence, the way the weights are updated in training neglects their effect early on in time. "),e.k0s(),e.qSk(),e.j41(173,"svg",93)(174,"text",94),e.EFF(175,"y = 0.25"),e.k0s(),e.nrm(176,"line",95)(177,"line",96)(178,"line",97),e.j41(179,"text",98),e.EFF(180,"y = 1"),e.k0s(),e.nrm(181,"line",99)(182,"line",100)(183,"line",101),e.j41(184,"text",102),e.EFF(185," (sigmoid) "),e.k0s(),e.j41(186,"text",103),e.EFF(187," (derivatives are in red) "),e.k0s(),e.j41(188,"text",104),e.EFF(189," (tanh) "),e.k0s(),e.DNE(190,Me,5,8,"g",105),e.k0s(),e.joV(),e.j41(191,"p"),e.EFF(192," There\u2019s also an issue of \u2018exploding\u2019 gradients, which might happen when the activation functions used can have large derivatives (such as the logarithm near \\(0\\)). This causes the weights to be changed too coarsely. "),e.k0s(),e.j41(193,"p"),e.EFF(194," However, this is not a dead end! Some RNN variations address this issue. Enter... LSTMs! "),e.k0s(),e.j41(195,"h3"),e.EFF(196,"Long Short-Term Memory Networks"),e.k0s(),e.j41(197,"p")(198,"a",106),e.EFF(199,"Invented by Josef Hochreiter and J\xfcrgen Schmidhuber in 1997"),e.k0s(),e.EFF(200,", LSTM (long short-term memory) networks are a more complex type of RNN which are designed to retain important information from iteration to iteration, all the while processing short-term aspects of the data. Each cell of an LSTM network has a line feeding through it through which information that is seldom modified is transported: the cell state, denoted by \\(c_t\\). LSTMs also contain \u2018gates\u2019: mechanisms which only allow certain information to pass through them. For example, the forget gate and input gate control changes to the cell state to ensure only long-term dependencies are stored in it. Additionally, there exists an output gate in each cell that decides which information in the cell state might be important to the next cell. Similar to conventional RNNs, LSTM networks directly pass this short-term information selected from the cell state from one cell to the next. This permits the network to focus on certain information that is pertinent at the moment, without losing information that is stored in the cell state. "),e.k0s(),e.j41(201,"p"),e.EFF(202," In the following diagrams, some arrows merge together. This was done so the diagrams could be more compact; the column vectors moving along the arrows are still referred to separately in the equations used here to describe their destination layers. Instead, an implementation of these layers could just concatenate the vectors and treat them with a single wider matrix of weights. "),e.k0s(),e.qSk(),e.j41(203,"svg",107)(204,"defs")(205,"g",108),e.nrm(206,"line",109)(207,"line",110),e.j41(208,"foreignObject",111),e.joV(),e.j41(209,"span",112),e.EFF(210),e.k0s()(),e.qSk(),e.j41(211,"foreignObject",113),e.joV(),e.j41(212,"span",112),e.EFF(213,"\\(x_t\\)"),e.k0s()()(),e.qSk(),e.j41(214,"g",114),e.nrm(215,"line",115),e.k0s(),e.j41(216,"g",116),e.nrm(217,"polyline",117)(218,"use",118),e.k0s(),e.j41(219,"g",119),e.nrm(220,"line",120)(221,"use",121),e.k0s(),e.j41(222,"g",122),e.nrm(223,"line",123),e.k0s(),e.j41(224,"g",124),e.nrm(225,"line",125),e.k0s(),e.j41(226,"g",126),e.nrm(227,"line",127)(228,"line",128)(229,"use",129)(230,"line",130)(231,"use",131),e.j41(232,"foreignObject",132),e.joV(),e.j41(233,"span",112),e.EFF(234,"\\(h_t\\)"),e.k0s()()(),e.qSk(),e.j41(235,"g",133),e.nrm(236,"line",134)(237,"use",135),e.k0s(),e.j41(238,"g",136),e.nrm(239,"line",55),e.j41(240,"foreignObject",137),e.joV(),e.j41(241,"span",112),e.EFF(242),e.k0s()(),e.qSk(),e.nrm(243,"line",138)(244,"use",139)(245,"line",140)(246,"use",141)(247,"line",142),e.j41(248,"foreignObject",143),e.joV(),e.j41(249,"span",112),e.EFF(250,"\\(c_t\\)"),e.k0s()()(),e.qSk(),e.j41(251,"g",144),e.nrm(252,"line",145),e.k0s(),e.j41(253,"g",146),e.nrm(254,"line",147)(255,"use",148),e.k0s(),e.j41(256,"g",149),e.nrm(257,"line",150)(258,"use",151),e.k0s(),e.j41(259,"g",152),e.nrm(260,"line",153),e.k0s(),e.j41(261,"g",154),e.nrm(262,"line",155),e.k0s()(),e.nrm(263,"use",156)(264,"use",157)(265,"use",158)(266,"use",159)(267,"use",160)(268,"use",161)(269,"use",162)(270,"use",163)(271,"use",164)(272,"use",165)(273,"use",166)(274,"use",167)(275,"use",168)(276,"use",169),e.j41(277,"g",170)(278,"text",171),e.EFF(279," \xa0forget gate "),e.k0s(),e.j41(280,"text",172),e.EFF(281," \xa0input gate "),e.k0s(),e.j41(282,"text",173),e.EFF(283," \xa0output gate "),e.k0s()()(),e.joV(),e.j41(284,"p"),e.EFF(285," To denote element-wise operations in the LSTM diagrams, a circular node is used with the operation\u2019s symbol inside, such as element-wise multiplication (\\(\\odot\\)) or addition (\\(+\\)). Let\u2019s now examine the gates and other components that make up the LSTM. "),e.k0s(),e.j41(286,"h4"),e.EFF(287,"Forget Gate"),e.k0s(),e.qSk(),e.j41(288,"svg",107),e.nrm(289,"use",156)(290,"use",166)(291,"use",167),e.j41(292,"g",174),e.nrm(293,"use",157)(294,"use",158)(295,"use",159)(296,"use",160)(297,"use",161)(298,"use",162)(299,"use",163)(300,"use",164)(301,"use",165)(302,"use",168)(303,"use",169),e.k0s()(),e.joV(),e.j41(304,"p"),e.EFF(305),e.k0s(),e.EFF(306),e.j41(307,"p"),e.EFF(308),e.k0s(),e.j41(309,"p"),e.EFF(310," The forget gate\u2019s (and other gates\u2019) activation vector contains values between zero and one to allow the old cell state to be multiplied element-wise by the activation vector and lessen unimportant values. For example: "),e.k0s(),e.EFF(311),e.j41(312,"p"),e.EFF(313," The \u20183\u2019 in the second vector is not of any importance according to the arbitrary activation vector on the left because the element it is multiplied by is \u20180\u2019. On the other hand, \u2018-7\u2019 is of utmost importance because the second element of the activation vector is \u20181\u2019, allowing it to pass unchanged. \u20185\u2019 is in between; it is of some importance because the corresponding activation vector element is \u20180.5\u2019, halving it. An activation vector is also called a mask because it \u2018masks\u2019 (allows only a fraction of a value to pass), in this case, the former cell state. "),e.k0s(),e.j41(314,"h4"),e.EFF(315,"Input Gate"),e.k0s(),e.qSk(),e.j41(316,"svg",107),e.nrm(317,"use",156)(318,"use",157)(319,"use",158)(320,"use",161),e.j41(321,"g",174),e.nrm(322,"use",159)(323,"use",160)(324,"use",162)(325,"use",163)(326,"use",164)(327,"use",165)(328,"use",166)(329,"use",167)(330,"use",168)(331,"use",169),e.k0s()(),e.joV(),e.j41(332,"p"),e.EFF(333),e.k0s(),e.EFF(334),e.j41(335,"p"),e.EFF(336," where \\(i_t\\) represents the activation vector, and \\(W_i\\), \\(U_i\\) and \\(b_i\\) represent the weights corresponding to \\(x_t\\), recurrent weights and the biases, respectively. "),e.k0s(),e.j41(337,"h4"),e.EFF(338,"Candidate Changes"),e.k0s(),e.qSk(),e.j41(339,"svg",107),e.nrm(340,"use",156)(341,"use",159)(342,"use",160)(343,"use",161)(344,"use",162),e.j41(345,"g",174),e.nrm(346,"use",157)(347,"use",158)(348,"use",163)(349,"use",164)(350,"use",165)(351,"use",166)(352,"use",167)(353,"use",168)(354,"use",169),e.k0s()(),e.joV(),e.j41(355,"p"),e.EFF(356," In addition to the sigmoid layer of the input gate, there exists a tanh layer that generates a vector of candidate changes to the cell state. Symbolically, this is written as: "),e.k0s(),e.EFF(357),e.j41(358,"p"),e.EFF(359," where \\(\\tilde c\\) represents the update candidates, and \\(W_c\\), \\(U_c\\) and \\(b_c\\) represent the weights corresponding to \\(x_t\\), the recurrent weights and the biases, respectively. The tanh activation function is used instead of sigmoid because changes to the cell state can be positive "),e.j41(360,"em"),e.EFF(361,"or negative"),e.k0s(),e.EFF(362,"; tanh\u2019s output ranges from -1 to 1 whereas sigmoid\u2019s is from 0 to 1, which is not appropriate. "),e.k0s(),e.j41(363,"p"),e.EFF(364," This is where the input gate comes into play: it chooses how potent each change will be on the cell state, if at all. Of course, this is done by taking the element-wise product of the activation vector and the vector of update candidates. Afterwards, this is added to the old cell state. "),e.k0s(),e.j41(365,"h4"),e.EFF(366,"Updating the Cell State"),e.k0s(),e.qSk(),e.j41(367,"svg",107)(368,"g",174),e.nrm(369,"use",156)(370,"use",157)(371,"use",159)(372,"use",161)(373,"use",162)(374,"use",163)(375,"use",164)(376,"use",165)(377,"use",166),e.k0s(),e.nrm(378,"use",158)(379,"use",160)(380,"use",167)(381,"use",168)(382,"use",169),e.k0s(),e.joV(),e.j41(383,"p"),e.EFF(384," Finally, the cell state can be updated. Once again: the old cell state is multiplied element-wise by the forget gate activation vector. Then, it is incremented by the element-wise product of the input gate activation vector and the candidate changes. Symbolically, this is written as: "),e.k0s(),e.EFF(385),e.j41(386,"p"),e.EFF(387," We\u2019re almost finished. Next, the new (short-term) output of the cell must be calculated. "),e.k0s(),e.j41(388,"h4"),e.EFF(389,"Output Gate"),e.k0s(),e.qSk(),e.j41(390,"svg",107),e.nrm(391,"use",163)(392,"use",164),e.j41(393,"g",174),e.nrm(394,"use",157)(395,"use",158)(396,"use",159)(397,"use",160)(398,"use",165)(399,"use",166)(400,"use",167)(401,"use",168)(402,"use",169),e.k0s(),e.nrm(403,"use",156)(404,"use",161)(405,"use",162),e.k0s(),e.joV(),e.j41(406,"p"),e.EFF(407),e.k0s(),e.EFF(408),e.j41(409,"p"),e.EFF(410," where \\(o_t\\) represents the new output mask, and \\(W_o\\), \\(U_o\\) and \\(b_o\\) represent the weights corresponding to \\(x_t\\), the recurrent weights and the biases, respectively. "),e.k0s(),e.j41(411,"h4"),e.EFF(412,"Cell Output"),e.k0s(),e.qSk(),e.j41(413,"svg",107)(414,"g",174),e.nrm(415,"use",156)(416,"use",157)(417,"use",158)(418,"use",159)(419,"use",160)(420,"use",161)(421,"use",162)(422,"use",163)(423,"use",166)(424,"use",167)(425,"use",168),e.k0s(),e.nrm(426,"use",164)(427,"use",165)(428,"use",169),e.k0s(),e.joV(),e.j41(429,"p"),e.EFF(430," Before we use the output layer\u2019s activation vector to select the pertinent information from the new cell state, we pass the cell state through the tanh activation function to map them between -1 and 1: "),e.k0s(),e.EFF(431," \\(h_t=o_t\\odot tanh(c_t)\\) "),e.j41(432,"p"),e.EFF(433," \\(c_t\\) is additionally fed through the tanh function instead of simply multiplying \\(o_t\\) and \\(c_t\\) element-wise so that the next cell\u2019s gates are not \u2018overpowered\u2019 by \\(c_t\\) in the product \\(h_t\\), pulling the outputs of the next cell\u2019s activation functions towards their maximum or minimum (hence almost fully opening or closing the gates). "),e.k0s(),e.j41(434,"h4"),e.EFF(435,"Round and Round..."),e.k0s(),e.j41(436,"p"),e.EFF(437),e.k0s(),e.j41(438,"p"),e.EFF(439," By now, I think it\u2019s pretty obvious that LSTMs are pretty complex, slowing down training and prediction. This is why we\u2019ll now look at a simpler (and faster) variant of LSTM networks. "),e.k0s(),e.j41(440,"h3"),e.EFF(441,"Gated Recurrent Unit"),e.k0s(),e.j41(442,"p"),e.EFF(443," The GRU (gated recurrent unit) was "),e.j41(444,"a",175),e.EFF(445,"introduced in 2014 by Kyunghyun Cho et al."),e.k0s(),e.EFF(446," and is simpler than the original LSTM: the whole of the cell state is encapsulated in the output of the cell and the forget gate and input gate are combined into an update gate. The output gate is removed and a new reset gate is added that decides how much the update to the old cell state will depend on the values of the old cell state, similar to the output gate of an LSTM, which decides how useful the cell state will be for the next cell\u2019s gates. Although simpler, GRUs have proved to have a comparative accuracy as LSTM networks (and even a better one for smaller training datasets), with the benefit of less operations. We\u2019ll now quickly go over how a GRU works. "),e.k0s(),e.qSk(),e.j41(447,"svg",176)(448,"defs")(449,"g",177),e.nrm(450,"line",110),e.j41(451,"foreignObject",113),e.joV(),e.j41(452,"span",178),e.EFF(453,"\\(x_t\\)"),e.k0s()()(),e.qSk(),e.j41(454,"g",179),e.nrm(455,"line",180),e.j41(456,"foreignObject",181),e.joV(),e.j41(457,"span",112),e.EFF(458),e.k0s()()(),e.qSk(),e.j41(459,"g",182),e.nrm(460,"line",183)(461,"line",184)(462,"line",185),e.k0s(),e.j41(463,"g",186),e.nrm(464,"line",187)(465,"use",188),e.k0s(),e.j41(466,"g",189),e.nrm(467,"line",120),e.k0s(),e.j41(468,"g",190),e.nrm(469,"line",191)(470,"line",192)(471,"use",193),e.k0s(),e.j41(472,"g",194),e.nrm(473,"line",195)(474,"polyline",196)(475,"line",197)(476,"use",198)(477,"use",199),e.k0s(),e.j41(478,"g",200),e.nrm(479,"line",201)(480,"line",202)(481,"use",203),e.k0s(),e.j41(482,"g",204),e.nrm(483,"line",205),e.k0s(),e.j41(484,"g",206),e.nrm(485,"line",207)(486,"line",208)(487,"line",209)(488,"line",207)(489,"line",142)(490,"line",210)(491,"use",211)(492,"use",212)(493,"use",213)(494,"use",214),e.j41(495,"foreignObject",215),e.joV(),e.j41(496,"span",112),e.EFF(497,"\\(h_t\\)"),e.k0s()()()(),e.qSk(),e.nrm(498,"use",216)(499,"use",217)(500,"use",218)(501,"use",219)(502,"use",220)(503,"use",221)(504,"use",222)(505,"use",223)(506,"use",224)(507,"use",225),e.j41(508,"g",170)(509,"text",226),e.EFF(510,"\xa0reset gate"),e.k0s(),e.j41(511,"text",227),e.EFF(512,"\xa0update gate"),e.k0s()()(),e.joV(),e.j41(513,"h4"),e.EFF(514,"Reset Gate"),e.k0s(),e.qSk(),e.j41(515,"svg",176),e.nrm(516,"use",217)(517,"use",221)(518,"use",222)(519,"use",218)(520,"use",223),e.j41(521,"g",174),e.nrm(522,"use",219)(523,"use",216)(524,"use",220)(525,"use",224)(526,"use",225),e.k0s()(),e.joV(),e.j41(527,"p"),e.EFF(528," The reset gate, one of the two gates of a GRU, decides how important each element of the previous cell state is in computing the candidate changes to cell state based on the previous cell state and the current timestep\u2019s input: "),e.k0s(),e.EFF(529),e.j41(530,"p"),e.EFF(531),e.k0s(),e.j41(532,"p"),e.EFF(533," The reset gate\u2019s name comes from what happens when its activation vector\u2019s values are very small or equal to zero: the previous cell state is neglected and the current input exclusively determines the candidate changes. "),e.k0s(),e.j41(534,"h4"),e.EFF(535,"Candidate Changes"),e.k0s(),e.qSk(),e.j41(536,"svg",176)(537,"defs")(538,"mask",228),e.nrm(539,"rect",229)(540,"use",230),e.k0s()(),e.nrm(541,"use",219)(542,"use",224),e.j41(543,"g",174),e.nrm(544,"use",216)(545,"use",217)(546,"use",216)(547,"use",222)(548,"use",221)(549,"use",220)(550,"use",225),e.k0s(),e.nrm(551,"use",231)(552,"use",221)(553,"use",223),e.k0s(),e.joV(),e.j41(554,"p"),e.EFF(555," To decide on candidate changes to the cell state, a tanh layer is fed the vector with old cell state information, filtered by the reset gate, in addition to the current timestep\u2019s input: "),e.k0s(),e.EFF(556),e.j41(557,"p"),e.EFF(558," Similar to LSTMs, \\(\\tilde h_t\\) is a vector of candidate changes to the cell state that will be further filtered by the update gate and applied to the cell state after it forgets irrelevant details. "),e.k0s(),e.j41(559,"h4"),e.EFF(560,"Update Gate"),e.k0s(),e.qSk(),e.j41(561,"svg",176),e.nrm(562,"use",216)(563,"use",220),e.j41(564,"g",174),e.nrm(565,"use",217)(566,"use",218)(567,"use",219)(568,"use",224)(569,"use",225),e.k0s(),e.nrm(570,"use",221)(571,"use",222)(572,"use",223),e.k0s(),e.joV(),e.j41(573,"p"),e.EFF(574," The update gate of a GRU replaces the functionality of the forget and input gates of an LSTM network. It constitutes of a sigmoid-activated layer that is trained to decide how much to update each field of the cell state. The update gate activation vector can be represented as follows: "),e.k0s(),e.EFF(575),e.j41(576,"p"),e.EFF(577," Each element of \\(z_t\\) signifies how much the corresponding element of the cell state will be forgotten, from zero to one. Since the update gate also functions as an input gate, it represents how potent each candidate change against the cell state will be. "),e.k0s(),e.j41(578,"h4"),e.EFF(579,"Cell State"),e.k0s(),e.qSk(),e.j41(580,"svg",176)(581,"defs")(582,"g",232),e.nrm(583,"use",221)(584,"use",217)(585,"use",218)(586,"use",219)(587,"use",222)(588,"use",216),e.k0s(),e.j41(589,"mask",233),e.nrm(590,"rect",234)(591,"use",235),e.k0s()(),e.nrm(592,"use",236)(593,"use",220)(594,"use",224)(595,"use",225)(596,"use",223),e.k0s(),e.joV(),e.j41(597,"p"),e.EFF(598,"Finally, the new cell state can be constructed and sent out:"),e.k0s(),e.EFF(599),e.j41(600,"p"),e.EFF(601," In the expression above, \\(z_t\\) is being subtracted from \u20181\u2019 because the update gate of a GRU forgets the information it will replace. In this case, \\(z_t\\) represents how much the candidate changes will affect the cell state and thus the old cell state is multiplied element-wise by \\(1-z_t\\) because the larger an element of \\(z_t\\) is, the smaller \\(1-z_t\\) will be, leading to less of the element in question of the cell state being preserved, and vice versa. "),e.k0s(),e.EFF(602," \u2042 "),e.j41(603,"p"),e.EFF(604," By now, Alice is convinced that RNNs, particularly LSTM networks or GRUs are the tools she needs for her job; they can be fed variable-size inputs and the latter two can retain information over many timesteps. However, she still needs to figure out a way to encode the words in her reviews as numbers, preferrably grouping together the representations of words that have similar meanings. "),e.k0s(),e.j41(605,"h2"),e.EFF(606,"Text vectorisation"),e.k0s(),e.j41(607,"p"),e.EFF(608," The vocabulary of the network can be represented as a list of known words, each with a numerical index. To convert a textual input into a numerical one, the words are substituted with the indices. Sometimes, the indices are assigned with purpose, and less frequent words might not receive an index. "),e.k0s(),e.j41(609,"p"),e.EFF(610," However, sentences that include words which are not part of the existing vocabulary cannot be encoded. To solve this, there can be an additional index for unknown words. This way, the structure of the sample is preserved, whereas simply omitting unknown words could encourage the neural network to misunderstand the sentence. "),e.k0s(),e.j41(611,"h2"),e.EFF(612,"Embedding"),e.k0s(),e.j41(613,"p"),e.EFF(614," To alleviate the network of coming up with a more semantic representation of these indices, the indices undergo \u2018embedding\u2019, which replaces each index with a vector that best represents the corresponding word\u2019s meaning. Now, the RNN can operate on meanings instead of on the words that denote them. For example, \u2018child\u2019 and \u2018kid\u2019 should be assigned similar vectors. "),e.k0s(),e.j41(615,"h2"),e.EFF(616,"Putting It All Together"),e.k0s(),e.j41(617,"p"),e.EFF(618," Now, we\u2019ll go over the code that will train a model to suggest ratings to customers. We\u2019ll do this with TensorFlow, using the Keras interface because of its rich functionality and the small amount of code we would need to write to use it. TensorFlow currently provides language bindings from C++ to Python, Java, C and Go, in addition to a JavaScript API. There also exist community-provided bindings to other languages. However, we\u2019ll write our program in Python because TensorFlow\u2019s documentation references the Python library. "),e.k0s(),e.j41(619,"p"),e.EFF(620," Keras is an abstraction of TensorFlow, which simplifies designing models of various architectures. Every model built with Keras consists of layers, which are different functions the inputs to the model can pass through, ranging from dense (feed-forward) layers to recurrent ones. Keras provides two APIs: \u2018sequential\u2019 and \u2018functional\u2019. The sequential API enables one to easily create a model where the output of each layer is the input to the next. For more complex use-cases, the functional API can be utilised to reuse layer outputs to be given to multiple following layers. We are going use the sequential API to write our code because we simply need to stack layers one on top of the next. "),e.k0s(),e.j41(621,"p"),e.EFF(622," If you prefer to go over the already-written code, a Jupyter notebook filled with it is available "),e.j41(623,"a",237),e.EFF(624,"here"),e.k0s(),e.EFF(625,". You can also "),e.j41(626,"a",238),e.EFF(627,"import the notebook into Google Colaboratory"),e.k0s(),e.EFF(628," to run it remotely. If you decide to go with the latter, I suggest you switch to a GPU-accelerated runtime to speed up training by navigating to \u2018Runtime\u2019 > \u2018Change runtime type\u2019 (in the menubar) and selecting GPU in the drop-down. Note that you might run into usage limits if you use this runtime for too long, so consider switching back to the CPU backend (\u2018None\u2019 dropdown option) when finished. "),e.k0s(),e.j41(629,"h3"),e.EFF(630,"Configuring Your Environment"),e.k0s(),e.j41(631,"p"),e.EFF(632,"To begin, install or upgrade the Python TensorFlow library using pip:"),e.k0s(),e.j41(633,"app-cell"),e.EFF(634,"$ pip install --upgrade tensorflow"),e.k0s(),e.EFF(635," Output: "),e.j41(636,"pre")(637,"code"),e.EFF(638,"Requirement already satisfied: tensorflow in ./.venv/lib/python3.9/site-packages (2.6.0)\nRequirement already satisfied: termcolor~=1.1.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: six~=1.15.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: tensorflow-estimator~=2.6 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: tensorboard~=2.6 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: clang~=5.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (5.0)\nRequirement already satisfied: keras~=2.6 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: grpcio<2.0,>=1.37.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.39.0)\nRequirement already satisfied: wrapt~=1.12.1 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: wheel~=0.35 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: protobuf>=3.9.2 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.17.3)\nRequirement already satisfied: astunparse~=1.6.3 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: opt-einsum~=3.3.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: absl-py~=0.10 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.13.0)\nRequirement already satisfied: numpy~=1.19.2 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.19.5)\nRequirement already satisfied: typing-extensions~=3.7.4 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.7.4.3)\nRequirement already satisfied: gast==0.4.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: h5py~=3.1.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (1.12)\nRequirement already satisfied: google-pasta~=0.2 in ./.venv/lib/python3.9/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\nRequirement already satisfied: werkzeug>=0.11.15 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\nRequirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.5)\nRequirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\nRequirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\nRequirement already satisfied: google-auth<2,>=1.6.3 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.34.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in ./.venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./.venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\nRequirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\nRequirement already satisfied: charset-normalizer~=2.0.0 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\nRequirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)"),e.k0s()(),e.j41(639,"p"),e.EFF(640," Usually, one would do this in a virtual environment to leave the user-wide site-packages clean. If you\u2019re interested in doing that, take a look at "),e.j41(641,"a",239),e.EFF(642,"this"),e.k0s(),e.EFF(643,". "),e.k0s(),e.j41(644,"p"),e.EFF(645," Next, we import TensorFlow, in addition to "),e.j41(646,"code"),e.EFF(647,"urllib"),e.k0s(),e.EFF(648," and "),e.j41(649,"code"),e.EFF(650,"zlib"),e.k0s(),e.EFF(651," which we will use to load an Amazon book review dataset (let\u2019s just say Alice doesn\u2019t have enough reviews herself). We also import "),e.j41(652,"code"),e.EFF(653,"datetime"),e.k0s(),e.EFF(654," and "),e.j41(655,"code"),e.EFF(656,"os"),e.k0s(),e.EFF(657," to set up log directories for TensorBoard, a web-based utility for inspecting models and monitoring training: "),e.k0s(),e.nrm(658,"app-cell",240),e.j41(659,"p"),e.EFF(660," Now, we define some constants that we will later use in our program. "),e.k0s(),e.nrm(661,"app-cell",240),e.j41(662,"h3"),e.EFF(663,"Loading the Dataset"),e.k0s(),e.j41(664,"p"),e.EFF(665," To load the Amazon review dataset, we\u2019ll use a custom generator ("),e.j41(666,"code"),e.EFF(667,"ds_lines"),e.k0s(),e.EFF(668,") that will decompress the TSV file chunk by chunk, then yield it line by line. This way, only the number of reviews we actually want to use (out of the 10 319 090) will be downloaded. For reference, this dataset was found on "),e.j41(669,"a",241),e.EFF(670,"the TensorFlow datasets overview page"),e.k0s(),e.EFF(671,". We\u2019ll also add in the function ("),e.j41(672,"code"),e.EFF(673,"ds_tuples"),e.k0s(),e.EFF(674,") which takes a scalar string tensor "),e.j41(675,"code"),e.EFF(676,"line"),e.k0s(),e.EFF(677," as input, parses it and returns the review body and numerical rating so that the rest of the review doesn\u2019t get in our way. "),e.k0s(),e.nrm(678,"app-cell",240),e.j41(679,"p"),e.EFF(680," To simplify pouring the dataset into the model, we\u2019ll use the "),e.j41(681,"code"),e.EFF(682,"tf.data.Dataset"),e.k0s(),e.EFF(683," class to create a TensorFlow input pipeline, which we\u2019ll later use to prepare the dataset and feed it into the model. An input pipeline is a process each element of a dataset is passed through to become a value that can be given to a model. The "),e.j41(684,"code"),e.EFF(685,"tf.data.Dataset"),e.k0s(),e.EFF(686," class also has the added benefit that the whole dataset does not have to be stored in memory to be read from, meaning large datasets can be split up into portions cached on disk, in addition to other convenient methods to improve training efficiency. "),e.k0s(),e.nrm(687,"app-cell",240),e.j41(688,"h3"),e.EFF(689,"Assembling the Model"),e.k0s(),e.j41(690,"p"),e.EFF(691," Finally, we can build our model. To begin, we create a Keras text vectorisation layer and tweaks it so it indexes all the words in the training dataset. "),e.k0s(),e.nrm(692,"app-cell",240),e.j41(693,"p"),e.EFF(694," Next, we uses the "),e.j41(695,"code"),e.EFF(696,"tf.keras.Sequential"),e.k0s(),e.EFF(697," class to create a new model with an embedding layer to learn the meanings of the encoder\u2019s words, a bidirectional GRU layer to process the review, a dense layer to process the output of the GRU and another dense layer to encode the output as a one-hot vector (a vector filled with zeroes except for a one whose index matches the encoded rating, in this case). "),e.k0s(),e.nrm(698,"app-cell",240),e.j41(699,"p"),e.EFF(700," After creating the model, we configure which optimiser and loss function it will use during training, in addition to specifying that we would like TensorFlow to report the accuracy of the model each epoch. The "),e.j41(701,"code"),e.EFF(702,"tf.keras.losses.SparseCategoricalCrossentropy"),e.k0s(),e.EFF(703," loss compares the output of the model to the correct numerical rating encoded as a one-hot vector. The "),e.j41(704,"code"),e.EFF(705,"from_logits"),e.k0s(),e.EFF(706," parameter indicates that the loss function should expect the output from the last layer of the model to not have passed through an activation function. This is preferred because an activation function, such as sigmoid, can degrade the precision of the output of the network, rendering the loss function less effective. "),e.k0s(),e.nrm(707,"app-cell",240),e.j41(708,"h3"),e.EFF(709,"Training"),e.k0s(),e.j41(710,"p"),e.EFF(711," Before training the network, you should create a TensorBoard callback to write log files while training the model: "),e.k0s(),e.nrm(712,"app-cell",240),e.j41(713,"p"),e.EFF(714," Afterwards, you can start TensorBoard take a look at how the model is doing during training in real time by running: "),e.k0s(),e.j41(715,"app-cell"),e.EFF(716,"$ tensorboard --logdir logs/"),e.k0s(),e.EFF(717," Output: "),e.j41(718,"pre")(719,"code"),e.EFF(720,"Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\nTensorBoard 2.6.0 at http://localhost:6007/ (Press CTRL+C to quit)"),e.k0s()(),e.j41(721,"p"),e.EFF(722," Then, you can open your browser to "),e.j41(723,"a",242),e.EFF(724,"http://localhost:6006"),e.k0s(),e.EFF(725," (TensorBoard\u2019s web interface). "),e.k0s(),e.j41(726,"p"),e.EFF(727," We can now begin training the network. A Keras model is trained by calling "),e.j41(728,"code"),e.EFF(729,".fit"),e.k0s(),e.EFF(730," on it and passing relevant parameters, such as "),e.j41(731,"code"),e.EFF(732,"validation_data"),e.k0s(),e.EFF(733," (specifying the data to be used to evaluate the model after training for an epoch) and "),e.j41(734,"code"),e.EFF(735,"epochs"),e.k0s(),e.EFF(736," (the number of iterations over the entire dataset). "),e.k0s(),e.nrm(737,"app-cell",240),e.j41(738,"p"),e.EFF(739," Now, you can click on the refresh button in the top-right corner of TensorBoard to load the training logs. Afterwards, be sure you are on the \u2018SCALARS\u2019 tab to see the loss and accuracy (select it from the toolbar at the top of the screen). You will have to continue reloading TensorBoard (or enable periodic reloading by clicking on the settings icon in the top-right corner) to view the new logs. Once training is over, TensorBoard should look like this: "),e.k0s(),e.nrm(740,"img",243),e.j41(741,"h3"),e.EFF(742,"Inference!"),e.k0s(),e.j41(743,"p"),e.EFF(744,"Lastly, you can predict a rating on your very own fictional review:"),e.k0s(),e.nrm(745,"app-cell",240),e.j41(746,"h2"),e.EFF(747,"Conclusion"),e.k0s(),e.j41(748,"p"),e.EFF(749," Recurrent neural networks are a great approach to processing interconnected data of varying lengths. However, training vanilla RNNs becomes difficult if gradients vanish or explode. Vanilla RNNs also have a hard time retaining information for many iterations because they just don\u2019t have a dedicated mechanism to store it and learning how to do it themselves proves to be mostly unsuccessful. Luckily, different RNN adaptations exist, such as the LSTM and GRU, that are designed to preserve more information over time and, as an effect, prevent gradients from vanishing. To demonstrate the approach to classifying text using a GRU, we went through the example of an online bookstore and built a book review classifier using TensorFlow. "),e.k0s(),e.j41(750,"p"),e.EFF(751," I hope you found this post useful. If you have any feedback, please drop me a line on "),e.j41(752,"a",244),e.EFF(753,"GitHub Discussions"),e.k0s(),e.EFF(754,". Thank you! "),e.k0s(),e.j41(755,"h2"),e.EFF(756,"References"),e.k0s(),e.j41(757,"p"),e.EFF(758," This post relies on information from the following sources: "),e.k0s(),e.j41(759,"ul")(760,"li")(761,"a",245),e.EFF(762," Wikipedia - Recurrent neural network "),e.k0s()(),e.j41(763,"li")(764,"a",246),e.EFF(765," Wikipedia - Bidirectional recurrent neural networks "),e.k0s()(),e.j41(766,"li")(767,"a",247),e.EFF(768," Wikipedia - Vanishing gradient problem "),e.k0s()(),e.j41(769,"li")(770,"a",248),e.EFF(771," colah's blog - Understanding LSTM Networks "),e.k0s()(),e.j41(772,"li")(773,"a",249),e.EFF(774," Wikipedia - Gated recurrent unit "),e.k0s()(),e.j41(775,"li")(776,"a",250),e.EFF(777," TensorFlow Documentation - tf.keras.layers.TextVectorization "),e.k0s()(),e.j41(778,"li")(779,"a",251),e.EFF(780," TensorFlow Documentation - tf.keras.layers.Embedding "),e.k0s()(),e.j41(781,"li")(782,"a",252),e.EFF(783," TensorFlow Tutorials - Text classification with an RNN "),e.k0s()()()()),2&u&&(e.R7$(96),e.SpI(" Now let\u2019s look at a concrete example of a cell. In the figure below we represent a layer as a black square that at timestep \\(t\\) computes its output \\(h_t\\) based on the value of the previous cell \\(h_","{t-1}","\\) and the input \\(x_t\\) using the sigmoid activation function. This layer is the RNN\u2019s cell. "),e.R7$(9),e.SpI("\\(h_","{t-1}","\\)"),e.R7$(7),e.SpI(" To express all this symbolically, we\u2019ll consider \\(W\\) as the matrix of weights that are to be applied to \\(x_t\\), where each row in \\(W\\) corresponds to a neuron in the cell. Another matrix of weights, \\(U\\), is applied to the previous cell\u2019s output \\(h_","{t-1}","\\). A bias (\\(b\\)) is also added to offset the sum to a desired value. Finally, the output of the cell at time t will be: "),e.R7$(),e.SpI(" \\(h_t=\\sigma (Wx_t+Uh_","{t-1}","+b)\\) "),e.R7$(77),e.Y8G("ngForOf",j.xValues),e.R7$(20),e.SpI("\\(h_","{t-1}","\\)"),e.R7$(32),e.SpI("\\(c_","{t-1}","\\)"),e.R7$(63),e.SpI(" Notably, the forget gate in an LSTM decides what information should be kept in the cell state. It does so by examining the current input (\\(x_t\\)) and the output vector of the previous cell (\\(h_","{t-1}","\\)) to decide how important the values in the cell state (which is a vector) are. This is done with the first sigmoid layer in the LSTM, which outputs a vector with values ranging between zero (not of importance) and one (of utmost importance) This is referred to as the forget gate\u2019s activation vector. The forget gate is expressed as: "),e.R7$(),e.SpI(" \\(f_t=\\sigma(W_fx_t+U_fh_","{t-1}","+b_f)\\) "),e.R7$(2),e.SpI(" where \\(f_t\\) represents the activation vector, and \\(W_f\\), \\(U_f\\) and \\(b_f\\) represent the weights corresponding to \\(x_t\\), the weights corresponding to \\(h_","{t-1}","\\) (named the \u2018recurrent weights\u2019) and the biases, respectively. "),e.R7$(3),e.ZXR(" \\(\\begin","{bmatrix}"," 0 \\\\ 1 \\\\ 0.5 \\end","{bmatrix}"," \\odot \\begin","{bmatrix}"," 3 \\\\ -7 \\\\ 5 \\end","{bmatrix}"," = \\begin","{bmatrix}"," 0 \\\\ -7 \\\\ 2.5 \\end","{bmatrix}","\\) "),e.R7$(22),e.SpI(" Similar to the forget gate, the input gate is also equipped with a sigmoid layer which takes \\(x_t\\) and \\(h_","{t-1}","\\) as inputs. However, this gate decides which values of the cell state should be updated based on the current input and the old cell state. This gate is written as: "),e.R7$(),e.SpI(" \\(i_t=\\sigma(W_ix_t+U_ih_","{t-1}","+b_i)\\) "),e.R7$(23),e.SpI(" \\(\\tilde c=tanh(W_cx_t+U_ch_","{t-1}","+b_c)\\) "),e.R7$(28),e.SpI(" \\(c_t=f_t\\odot c_","{t-1}","+i_t\\odot \\tilde c\\) "),e.R7$(22),e.SpI(" Our cell state is now updated, but we still need to select which information we would like to output from our cell. This is the purpose of the output gate. First, we use a sigmoid layer (as always) to decide which fields of the cell state are pertinent to the next cell based on \\(x_t\\) and \\(h_","{t-1}","\\): "),e.R7$(),e.SpI(" \\(o_t=\\sigma(W_ox_t+U_oh_","{t-1}","+b_o)\\) "),e.R7$(29),e.Lme(" The above process repeats for every new input to the LSTM network (e.g. every word in the book review). At the beginning, when \\(t=0\\), \\(c_","{t-1}","\\) and \\(h_","{t-1}","\\) are considered to be vectors filled with zeroes to give the LSTM a clean slate to write on. The retention of information in the cell-state by not applying an activation function to it, for example, reduces the vanishing gradient problem. "),e.R7$(21),e.SpI("\\(h_","{t-1}","\\)"),e.R7$(71),e.SpI(" \\(r_t=\\sigma(W_rx_t+U_rh_","{t-1}","+b_r)\\) "),e.R7$(2),e.SpI(" \\(r_t\\) represents the activation vector of the reset gate, which will later be multiplied element-wise with \\(h_","{t-1}","\\) to filter out relevant information. "),e.R7$(25),e.SpI(" \\(\\tilde h_t=tanh(W_hx_t+U_h(r_t\\odot h_","{t-1}",")+b_h)\\) "),e.R7$(19),e.SpI(" \\(z_t=\\sigma(W_zx_t+U_zh_","{t-1}","+b_z)\\) "),e.R7$(24),e.SpI(" \\(h_t=(1-z_t)\\odot h_","{t-1}","+z_t\\odot\\tilde h_t\\) "),e.R7$(59),e.Y8G("index",3),e.R7$(3),e.Y8G("index",4),e.R7$(17),e.Y8G("index",6),e.R7$(9),e.Y8G("index",7),e.R7$(5),e.Y8G("index",8),e.R7$(6),e.Y8G("index",9),e.R7$(9),e.Y8G("index",10),e.R7$(5),e.Y8G("index",11),e.R7$(25),e.Y8G("index",13),e.R7$(8),e.Y8G("index",14))},dependencies:[z.pM,he,xe],styles:["[_nghost-%COMP%]{background-color:linen;display:block;text-align:center;width:100%;min-height:100vh}#column[_ngcontent-%COMP%]{display:inline-block;box-sizing:border-box;max-width:min(40em,100%);overflow-wrap:break-word;padding:clamp(0px,50vw - 20em,20vh) 8px;text-align:center}#column[_ngcontent-%COMP%]   p[_ngcontent-%COMP%], #column[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{text-align:justify}#column[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{text-indent:2em}pre[_ngcontent-%COMP%]   code.hljs[_ngcontent-%COMP%], pre[_ngcontent-%COMP%]   [_ngcontent-%COMP%]:not(pre) > code[_ngcontent-%COMP%], pre[_ngcontent-%COMP%]   code.block[_ngcontent-%COMP%], pre[_ngcontent-%COMP%] > code[_ngcontent-%COMP%]{display:block;overflow-x:auto;padding:1em}code.hljs[_ngcontent-%COMP%], [_ngcontent-%COMP%]:not(pre) > code[_ngcontent-%COMP%], code.block[_ngcontent-%COMP%], pre[_ngcontent-%COMP%] > code[_ngcontent-%COMP%]{padding:3px 5px}\n\n\n\n\n\n\n\n\n\n.hljs[_ngcontent-%COMP%], [_ngcontent-%COMP%]:not(pre) > code[_ngcontent-%COMP%], .block[_ngcontent-%COMP%], pre[_ngcontent-%COMP%] > code[_ngcontent-%COMP%]{color:#c9d1d9;background:#0d1117}.hljs-doctag[_ngcontent-%COMP%], .hljs-keyword[_ngcontent-%COMP%], .hljs-meta[_ngcontent-%COMP%]   .hljs-keyword[_ngcontent-%COMP%], .hljs-template-tag[_ngcontent-%COMP%], .hljs-template-variable[_ngcontent-%COMP%], .hljs-type[_ngcontent-%COMP%], .hljs-variable.language_[_ngcontent-%COMP%]{color:#ff7b72}.hljs-title[_ngcontent-%COMP%], .hljs-title.class_[_ngcontent-%COMP%], .hljs-title.class_.inherited__[_ngcontent-%COMP%], .hljs-title.function_[_ngcontent-%COMP%]{color:#d2a8ff}.hljs-attr[_ngcontent-%COMP%], .hljs-attribute[_ngcontent-%COMP%], .hljs-literal[_ngcontent-%COMP%], .hljs-meta[_ngcontent-%COMP%], .hljs-number[_ngcontent-%COMP%], .hljs-operator[_ngcontent-%COMP%], .hljs-variable[_ngcontent-%COMP%], .hljs-selector-attr[_ngcontent-%COMP%], .hljs-selector-class[_ngcontent-%COMP%], .hljs-selector-id[_ngcontent-%COMP%]{color:#79c0ff}.hljs-regexp[_ngcontent-%COMP%], .hljs-string[_ngcontent-%COMP%], .hljs-meta[_ngcontent-%COMP%]   .hljs-string[_ngcontent-%COMP%]{color:#a5d6ff}.hljs-built_in[_ngcontent-%COMP%], .hljs-symbol[_ngcontent-%COMP%]{color:#ffa657}.hljs-comment[_ngcontent-%COMP%], .hljs-code[_ngcontent-%COMP%], .hljs-formula[_ngcontent-%COMP%]{color:#8b949e}.hljs-name[_ngcontent-%COMP%], .hljs-quote[_ngcontent-%COMP%], .hljs-selector-tag[_ngcontent-%COMP%], .hljs-selector-pseudo[_ngcontent-%COMP%]{color:#7ee787}.hljs-subst[_ngcontent-%COMP%]{color:#c9d1d9}.hljs-section[_ngcontent-%COMP%]{color:#1f6feb;font-weight:700}.hljs-bullet[_ngcontent-%COMP%]{color:#f2cc60}.hljs-emphasis[_ngcontent-%COMP%]{color:#c9d1d9;font-style:italic}.hljs-strong[_ngcontent-%COMP%]{color:#c9d1d9;font-weight:700}.hljs-addition[_ngcontent-%COMP%]{color:#aff5b4;background-color:#033a16}.hljs-deletion[_ngcontent-%COMP%]{color:#ffdcd7;background-color:#67060c}.block[_ngcontent-%COMP%], pre[_ngcontent-%COMP%] > code[_ngcontent-%COMP%]{border-radius:4px;font-family:inherit;padding:12px 16px;overflow-x:auto;text-align:left}.snippet[_ngcontent-%COMP%], [_ngcontent-%COMP%]:not(pre) > code[_ngcontent-%COMP%]{font-family:inherit;border-radius:2px;line-height:1.6em;padding:3px 4px}pre[_ngcontent-%COMP%]{font-family:inherit}polyline[_ngcontent-%COMP%]{fill:none}line[_ngcontent-%COMP%], polyline[_ngcontent-%COMP%]{stroke:#000;stroke-linecap:square;stroke-width:2px}line.arrow[_ngcontent-%COMP%], polyline.arrow[_ngcontent-%COMP%]{marker-end:url(#head)}line.diode[_ngcontent-%COMP%], polyline.diode[_ngcontent-%COMP%]{marker-end:url(#diode)}"]})}return d})()},{path:"**",redirectTo:""}]},6653:Be=>{function te(t){return t instanceof Map?t.clear=t.delete=t.set=function(){throw new Error("map is read-only")}:t instanceof Set&&(t.add=t.clear=t.delete=function(){throw new Error("set is read-only")}),Object.freeze(t),Object.getOwnPropertyNames(t).forEach(n=>{const i=t[n],f=typeof i;("object"===f||"function"===f)&&!Object.isFrozen(i)&&te(i)}),t}class R{constructor(n){void 0===n.data&&(n.data={}),this.data=n.data,this.isMatchIgnored=!1}ignoreMatch(){this.isMatchIgnored=!0}}function ne(t){return t.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;").replace(/"/g,"&quot;").replace(/'/g,"&#x27;")}function e(t,...n){const i=Object.create(null);for(const f in t)i[f]=t[f];return n.forEach(function(f){for(const x in f)i[x]=f[x]}),i}const re=t=>!!t.scope;class _e{constructor(n,i){this.buffer="",this.classPrefix=i.classPrefix,n.walk(this)}addText(n){this.buffer+=ne(n)}openNode(n){if(!re(n))return;const i=((t,{prefix:n})=>{if(t.startsWith("language:"))return t.replace("language:","language-");if(t.includes(".")){const i=t.split(".");return[`${n}${i.shift()}`,...i.map((f,x)=>`${f}${"_".repeat(x+1)}`)].join(" ")}return`${n}${t}`})(n.scope,{prefix:this.classPrefix});this.span(i)}closeNode(n){re(n)&&(this.buffer+="</span>")}value(){return this.buffer}span(n){this.buffer+=`<span class="${n}">`}}const ae=(t={})=>{const n={children:[]};return Object.assign(n,t),n};class z{constructor(){this.rootNode=ae(),this.stack=[this.rootNode]}get top(){return this.stack[this.stack.length-1]}get root(){return this.rootNode}add(n){this.top.children.push(n)}openNode(n){const i=ae({scope:n});this.add(i),this.stack.push(i)}closeNode(){if(this.stack.length>1)return this.stack.pop()}closeAllNodes(){for(;this.closeNode(););}toJSON(){return JSON.stringify(this.rootNode,null,4)}walk(n){return this.constructor._walk(n,this.rootNode)}static _walk(n,i){return"string"==typeof i?n.addText(i):i.children&&(n.openNode(i),i.children.forEach(f=>this._walk(n,f)),n.closeNode(i)),n}static _collapse(n){"string"!=typeof n&&n.children&&(n.children.every(i=>"string"==typeof i)?n.children=[n.children.join("")]:n.children.forEach(i=>{z._collapse(i)}))}}class le extends z{constructor(n){super(),this.options=n}addText(n){""!==n&&this.add(n)}startScope(n){this.openNode(n)}endScope(){this.closeNode()}__addSublanguage(n,i){const f=n.root;i&&(f.scope=`language:${i}`),this.add(f)}toHTML(){return new _e(this,this.options).value()}finalize(){return this.closeAllNodes(),!0}}function W(t){return t?"string"==typeof t?t:t.source:null}function ce(t){return B("(?=",t,")")}function Fe(t){return B("(?:",t,")*")}function ve(t){return B("(?:",t,")?")}function B(...t){return t.map(i=>W(i)).join("")}function ie(...t){return"("+(function Ee(t){const n=t[t.length-1];return"object"==typeof n&&n.constructor===Object?(t.splice(t.length-1,1),n):{}}(t).capture?"":"?:")+t.map(f=>W(f)).join("|")+")"}function he(t){return new RegExp(t.toString()+"|").exec("").length-1}const Me=/\[(?:[^\\\]]|\\.)*\]|\(\??|\\([1-9][0-9]*)|\\./;function ue(t,{joinWith:n}){let i=0;return t.map(f=>{i+=1;const x=i;let _=W(f),l="";for(;_.length>0;){const a=Me.exec(_);if(!a){l+=_;break}l+=_.substring(0,a.index),_=_.substring(a.index+a[0].length),"\\"===a[0][0]&&a[1]?l+="\\"+String(Number(a[1])+x):(l+=a[0],"("===a[0]&&i++)}return l}).map(f=>`(${f})`).join(n)}const d="[a-zA-Z]\\w*",T="[a-zA-Z_]\\w*",r="\\b\\d+(\\.\\d+)?",u="(-?)(\\b0[xX][a-fA-F0-9]+|(\\b\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)",j="\\b(0b[01]+)",N={begin:"\\\\[\\s\\S]",relevance:0},L={scope:"string",begin:"'",end:"'",illegal:"\\n",contains:[N]},V={scope:"string",begin:'"',end:'"',illegal:"\\n",contains:[N]},q=function(t,n,i={}){const f=e({scope:"comment",begin:t,end:n,contains:[]},i);f.contains.push({scope:"doctag",begin:"[ ]*(?=(TODO|FIXME|NOTE|BUG|OPTIMIZE|HACK|XXX):)",end:/(TODO|FIXME|NOTE|BUG|OPTIMIZE|HACK|XXX):/,excludeBegin:!0,relevance:0});const x=ie("I","a","is","so","us","to","at","if","in","it","on",/[A-Za-z]+['](d|ve|re|ll|t|s|n)/,/[A-Za-z]+[-][a-z]+/,/[A-Za-z][a-z]{2,}/);return f.contains.push({begin:B(/[ ]+/,"(",x,/[.]?[:]?([.][ ]|[ ])/,"){3}")}),f},D=q("//","$"),de=q("/\\*","\\*/"),U=q("#","$");var fe=Object.freeze({__proto__:null,APOS_STRING_MODE:L,BACKSLASH_ESCAPE:N,BINARY_NUMBER_MODE:{scope:"number",begin:j,relevance:0},BINARY_NUMBER_RE:j,COMMENT:q,C_BLOCK_COMMENT_MODE:de,C_LINE_COMMENT_MODE:D,C_NUMBER_MODE:{scope:"number",begin:u,relevance:0},C_NUMBER_RE:u,END_SAME_AS_BEGIN:function(t){return Object.assign(t,{"on:begin":(n,i)=>{i.data._beginMatch=n[1]},"on:end":(n,i)=>{i.data._beginMatch!==n[1]&&i.ignoreMatch()}})},HASH_COMMENT_MODE:U,IDENT_RE:d,MATCH_NOTHING_RE:/\b\B/,METHOD_GUARD:{begin:"\\.\\s*"+T,relevance:0},NUMBER_MODE:{scope:"number",begin:r,relevance:0},NUMBER_RE:r,PHRASAL_WORDS_MODE:{begin:/\b(a|an|the|are|I'm|isn't|don't|doesn't|won't|but|just|should|pretty|simply|enough|gonna|going|wtf|so|such|will|you|your|they|like|more)\b/},QUOTE_STRING_MODE:V,REGEXP_MODE:{scope:"regexp",begin:/\/(?=[^/\n]*\/)/,end:/\/[gimuy]*/,contains:[N,{begin:/\[/,end:/\]/,relevance:0,contains:[N]}]},RE_STARTERS_RE:"!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|-|-=|/=|/|:|;|<<|<<=|<=|<|===|==|=|>>>=|>>=|>=|>>>|>>|>|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~",SHEBANG:(t={})=>{const n=/^#![ ]*\//;return t.binary&&(t.begin=B(n,/.*\b/,t.binary,/\b.*/)),e({scope:"meta",begin:n,end:/$/,relevance:0,"on:begin":(i,f)=>{0!==i.index&&f.ignoreMatch()}},t)},TITLE_MODE:{scope:"title",begin:d,relevance:0},UNDERSCORE_IDENT_RE:T,UNDERSCORE_TITLE_MODE:{scope:"title",begin:T,relevance:0}});function it(t,n){"."===t.input[t.index-1]&&n.ignoreMatch()}function ot(t,n){void 0!==t.className&&(t.scope=t.className,delete t.className)}function rt(t,n){n&&t.beginKeywords&&(t.begin="\\b("+t.beginKeywords.split(" ").join("|")+")(?!\\.)(?=\\b|\\s)",t.__beforeBegin=it,t.keywords=t.keywords||t.beginKeywords,delete t.beginKeywords,void 0===t.relevance&&(t.relevance=0))}function at(t,n){Array.isArray(t.illegal)&&(t.illegal=ie(...t.illegal))}function lt(t,n){if(t.match){if(t.begin||t.end)throw new Error("begin & end are not supported with match");t.begin=t.match,delete t.match}}function ct(t,n){void 0===t.relevance&&(t.relevance=1)}const ht=(t,n)=>{if(!t.beforeMatch)return;if(t.starts)throw new Error("beforeMatch cannot be used with starts");const i=Object.assign({},t);Object.keys(t).forEach(f=>{delete t[f]}),t.keywords=i.keywords,t.begin=B(i.beforeMatch,ce(i.begin)),t.starts={relevance:0,contains:[Object.assign(i,{endsParent:!0})]},t.relevance=0,delete i.beforeMatch},ut=["of","and","for","in","not","or","if","then","parent","list","value"],dt="keyword";function Le(t,n,i=dt){const f=Object.create(null);return"string"==typeof t?x(i,t.split(" ")):Array.isArray(t)?x(i,t):Object.keys(t).forEach(function(_){Object.assign(f,Le(t[_],n,_))}),f;function x(_,l){n&&(l=l.map(a=>a.toLowerCase())),l.forEach(function(a){const g=a.split("|");f[g[0]]=[_,gt(g[0],g[1])]})}}function gt(t,n){return n?Number(n):function ft(t){return ut.includes(t.toLowerCase())}(t)?0:1}const qe={},K=t=>{console.error(t)},$e=(t,...n)=>{console.log(`WARN: ${t}`,...n)},Z=(t,n)=>{qe[`${t}/${n}`]||(console.log(`Deprecated as of ${t}. ${n}`),qe[`${t}/${n}`]=!0)},pe=new Error;function De(t,n,{key:i}){let f=0;const x=t[i],_={},l={};for(let a=1;a<=n.length;a++)l[a+f]=x[a],_[a+f]=!0,f+=he(n[a-1]);t[i]=l,t[i]._emit=_,t[i]._multi=!0}function bt(t){(function wt(t){t.scope&&"object"==typeof t.scope&&null!==t.scope&&(t.beginScope=t.scope,delete t.scope)})(t),"string"==typeof t.beginScope&&(t.beginScope={_wrap:t.beginScope}),"string"==typeof t.endScope&&(t.endScope={_wrap:t.endScope}),function pt(t){if(Array.isArray(t.begin)){if(t.skip||t.excludeBegin||t.returnBegin)throw K("skip, excludeBegin, returnBegin not compatible with beginScope: {}"),pe;if("object"!=typeof t.beginScope||null===t.beginScope)throw K("beginScope must be object"),pe;De(t,t.begin,{key:"beginScope"}),t.begin=ue(t.begin,{joinWith:""})}}(t),function mt(t){if(Array.isArray(t.end)){if(t.skip||t.excludeEnd||t.returnEnd)throw K("skip, excludeEnd, returnEnd not compatible with endScope: {}"),pe;if("object"!=typeof t.endScope||null===t.endScope)throw K("endScope must be object"),pe;De(t,t.end,{key:"endScope"}),t.end=ue(t.end,{joinWith:""})}}(t)}function yt(t){function n(l,a){return new RegExp(W(l),"m"+(t.case_insensitive?"i":"")+(t.unicodeRegex?"u":"")+(a?"g":""))}class i{constructor(){this.matchIndexes={},this.regexes=[],this.matchAt=1,this.position=0}addRule(a,g){g.position=this.position++,this.matchIndexes[this.matchAt]=g,this.regexes.push([g,a]),this.matchAt+=he(a)+1}compile(){0===this.regexes.length&&(this.exec=()=>null);const a=this.regexes.map(g=>g[1]);this.matcherRe=n(ue(a,{joinWith:"|"}),!0),this.lastIndex=0}exec(a){this.matcherRe.lastIndex=this.lastIndex;const g=this.matcherRe.exec(a);if(!g)return null;const E=g.findIndex((oe,Se)=>Se>0&&void 0!==oe),F=this.matchIndexes[E];return g.splice(0,E),Object.assign(g,F)}}class f{constructor(){this.rules=[],this.multiRegexes=[],this.count=0,this.lastIndex=0,this.regexIndex=0}getMatcher(a){if(this.multiRegexes[a])return this.multiRegexes[a];const g=new i;return this.rules.slice(a).forEach(([E,F])=>g.addRule(E,F)),g.compile(),this.multiRegexes[a]=g,g}resumingScanAtSamePosition(){return 0!==this.regexIndex}considerAll(){this.regexIndex=0}addRule(a,g){this.rules.push([a,g]),"begin"===g.type&&this.count++}exec(a){const g=this.getMatcher(this.regexIndex);g.lastIndex=this.lastIndex;let E=g.exec(a);if(this.resumingScanAtSamePosition()&&(!E||E.index!==this.lastIndex)){const F=this.getMatcher(0);F.lastIndex=this.lastIndex+1,E=F.exec(a)}return E&&(this.regexIndex+=E.position+1,this.regexIndex===this.count&&this.considerAll()),E}}if(t.compilerExtensions||(t.compilerExtensions=[]),t.contains&&t.contains.includes("self"))throw new Error("ERR: contains `self` is not supported at the top-level of a language.  See documentation.");return t.classNameAliases=e(t.classNameAliases||{}),function _(l,a){const g=l;if(l.isCompiled)return g;[ot,lt,bt,ht].forEach(F=>F(l,a)),t.compilerExtensions.forEach(F=>F(l,a)),l.__beforeBegin=null,[rt,at,ct].forEach(F=>F(l,a)),l.isCompiled=!0;let E=null;return"object"==typeof l.keywords&&l.keywords.$pattern&&(l.keywords=Object.assign({},l.keywords),E=l.keywords.$pattern,delete l.keywords.$pattern),E=E||/\w+/,l.keywords&&(l.keywords=Le(l.keywords,t.case_insensitive)),g.keywordPatternRe=n(E,!0),a&&(l.begin||(l.begin=/\B|\b/),g.beginRe=n(g.begin),!l.end&&!l.endsWithParent&&(l.end=/\B|\b/),l.end&&(g.endRe=n(g.end)),g.terminatorEnd=W(g.end)||"",l.endsWithParent&&a.terminatorEnd&&(g.terminatorEnd+=(l.end?"|":"")+a.terminatorEnd)),l.illegal&&(g.illegalRe=n(l.illegal)),l.contains||(l.contains=[]),l.contains=[].concat(...l.contains.map(function(F){return function kt(t){return t.variants&&!t.cachedVariants&&(t.cachedVariants=t.variants.map(function(n){return e(t,{variants:null},n)})),t.cachedVariants?t.cachedVariants:Ue(t)?e(t,{starts:t.starts?e(t.starts):null}):Object.isFrozen(t)?e(t):t}("self"===F?l:F)})),l.contains.forEach(function(F){_(F,g)}),l.starts&&_(l.starts,a),g.matcher=function x(l){const a=new f;return l.contains.forEach(g=>a.addRule(g.begin,{rule:g,type:"begin"})),l.terminatorEnd&&a.addRule(l.terminatorEnd,{type:"end"}),l.illegal&&a.addRule(l.illegal,{type:"illegal"}),a}(g),g}(t)}function Ue(t){return!!t&&(t.endsWithParent||Ue(t.starts))}class _t extends Error{constructor(n,i){super(n),this.name="HTMLInjectionError",this.html=i}}const Re=ne,Ge=e,He=Symbol("nomatch"),ze=function(t){const n=Object.create(null),i=Object.create(null),f=[];let x=!0;const _="Could not find the language '{}', did you forget to load/include a language module?",l={disableAutodetect:!0,name:"Plain text",contains:[]};let a={ignoreUnescapedHTML:!1,throwUnescapedHTML:!1,noHighlightRe:/^(no-?highlight)$/i,languageDetectRe:/\blang(?:uage)?-([\w-]+)\b/i,classPrefix:"hljs-",cssSelector:"pre code",languages:null,__emitter:le};function g(s){return a.noHighlightRe.test(s)}function F(s,h,w){let y="",v="";"object"==typeof h?(y=s,w=h.ignoreIllegals,v=h.language):(Z("10.7.0","highlight(lang, code, ...args) has been deprecated."),Z("10.7.0","Please use highlight(code, options) instead.\nhttps://github.com/highlightjs/highlight.js/issues/2277"),v=s,y=h),void 0===w&&(w=!0);const S={code:y,language:v};we("before:highlight",S);const H=S.result?S.result:oe(S.language,S.code,w);return H.code=S.code,we("after:highlight",H),H}function oe(s,h,w,y){const v=Object.create(null);function S(o,c){return o.keywords[c]}function H(){if(!p.keywords)return void M.addText(k);let o=0;p.keywordPatternRe.lastIndex=0;let c=p.keywordPatternRe.exec(k),m="";for(;c;){m+=k.substring(o,c.index);const b=I.case_insensitive?c[0].toLowerCase():c[0],O=S(p,b);if(O){const[$,Dt]=O;M.addText(m),m="",v[b]=(v[b]||0)+1,v[b]<=7&&(ke+=Dt),$.startsWith("_")?m+=c[0]:A(c[0],I.classNameAliases[$]||$)}else m+=c[0];o=p.keywordPatternRe.lastIndex,c=p.keywordPatternRe.exec(k)}m+=k.substring(o),M.addText(m)}function C(){null!=p.subLanguage?function be(){if(""===k)return;let o=null;if("string"==typeof p.subLanguage){if(!n[p.subLanguage])return void M.addText(k);o=oe(p.subLanguage,k,!0,Ze[p.subLanguage]),Ze[p.subLanguage]=o._top}else o=Te(k,p.subLanguage.length?p.subLanguage:null);p.relevance>0&&(ke+=o.relevance),M.__addSublanguage(o._emitter,o.language)}():H(),k=""}function A(o,c){""!==o&&(M.startScope(c),M.addText(o),M.endScope())}function Ye(o,c){let m=1;const b=c.length-1;for(;m<=b;){if(!o._emit[m]){m++;continue}const O=I.classNameAliases[o[m]]||o[m],$=c[m];O?A($,O):(k=$,H(),k=""),m++}}function Xe(o,c){return o.scope&&"string"==typeof o.scope&&M.openNode(I.classNameAliases[o.scope]||o.scope),o.beginScope&&(o.beginScope._wrap?(A(k,I.classNameAliases[o.beginScope._wrap]||o.beginScope._wrap),k=""):o.beginScope._multi&&(Ye(o.beginScope,c),k="")),p=Object.create(o,{parent:{value:p}}),p}function Je(o,c,m){let b=function je(t,n){const i=t&&t.exec(n);return i&&0===i.index}(o.endRe,m);if(b){if(o["on:end"]){const O=new R(o);o["on:end"](c,O),O.isMatchIgnored&&(b=!1)}if(b){for(;o.endsParent&&o.parent;)o=o.parent;return o}}if(o.endsWithParent)return Je(o.parent,c,m)}function It(o){return 0===p.matcher.regexIndex?(k+=o[0],1):(Ie=!0,0)}function Lt(o){const c=o[0],m=h.substring(o.index),b=Je(p,o,m);if(!b)return He;const O=p;p.endScope&&p.endScope._wrap?(C(),A(c,p.endScope._wrap)):p.endScope&&p.endScope._multi?(C(),Ye(p.endScope,o)):O.skip?k+=c:(O.returnEnd||O.excludeEnd||(k+=c),C(),O.excludeEnd&&(k=c));do{p.scope&&M.closeNode(),!p.skip&&!p.subLanguage&&(ke+=p.relevance),p=p.parent}while(p!==b.parent);return b.starts&&Xe(b.starts,o),O.returnEnd?0:c.length}let ye={};function Qe(o,c){const m=c&&c[0];if(k+=o,null==m)return C(),0;if("begin"===ye.type&&"end"===c.type&&ye.index===c.index&&""===m){if(k+=h.slice(c.index,c.index+1),!x){const b=new Error(`0 width match regex (${s})`);throw b.languageName=s,b.badRule=ye.rule,b}return 1}if(ye=c,"begin"===c.type)return function Bt(o){const c=o[0],m=o.rule,b=new R(m),O=[m.__beforeBegin,m["on:begin"]];for(const $ of O)if($&&($(o,b),b.isMatchIgnored))return It(c);return m.skip?k+=c:(m.excludeBegin&&(k+=c),C(),!m.returnBegin&&!m.excludeBegin&&(k=c)),Xe(m,o),m.returnBegin?0:c.length}(c);if("illegal"===c.type&&!w){const b=new Error('Illegal lexeme "'+m+'" for mode "'+(p.scope||"<unnamed>")+'"');throw b.mode=p,b}if("end"===c.type){const b=Lt(c);if(b!==He)return b}if("illegal"===c.type&&""===m)return 1;if(Ae>1e5&&Ae>3*c.index)throw new Error("potential infinite loop, way more iterations than matches");return k+=m,m.length}const I=G(s);if(!I)throw K(_.replace("{}",s)),new Error('Unknown language: "'+s+'"');const $t=yt(I);let Ne="",p=y||$t;const Ze={},M=new a.__emitter(a);!function qt(){const o=[];for(let c=p;c!==I;c=c.parent)c.scope&&o.unshift(c.scope);o.forEach(c=>M.openNode(c))}();let k="",ke=0,Y=0,Ae=0,Ie=!1;try{if(I.__emitTokens)I.__emitTokens(h,M);else{for(p.matcher.considerAll();;){Ae++,Ie?Ie=!1:p.matcher.considerAll(),p.matcher.lastIndex=Y;const o=p.matcher.exec(h);if(!o)break;const m=Qe(h.substring(Y,o.index),o);Y=o.index+m}Qe(h.substring(Y))}return M.finalize(),Ne=M.toHTML(),{language:s,value:Ne,relevance:ke,illegal:!1,_emitter:M,_top:p}}catch(o){if(o.message&&o.message.includes("Illegal"))return{language:s,value:Re(h),illegal:!0,relevance:0,_illegalBy:{message:o.message,index:Y,context:h.slice(Y-100,Y+100),mode:o.mode,resultSoFar:Ne},_emitter:M};if(x)return{language:s,value:Re(h),illegal:!1,relevance:0,errorRaised:o,_emitter:M,_top:p};throw o}}function Te(s,h){h=h||a.languages||Object.keys(n);const w=function Se(s){const h={value:Re(s),illegal:!1,relevance:0,_top:l,_emitter:new a.__emitter(a)};return h._emitter.addText(s),h}(s),y=h.filter(G).filter(Ke).map(C=>oe(C,s,!1));y.unshift(w);const v=y.sort((C,A)=>{if(C.relevance!==A.relevance)return A.relevance-C.relevance;if(C.language&&A.language){if(G(C.language).supersetOf===A.language)return 1;if(G(A.language).supersetOf===C.language)return-1}return 0}),[S,H]=v,be=S;return be.secondBest=H,be}function Pe(s){let h=null;const w=function E(s){let h=s.className+" ";h+=s.parentNode?s.parentNode.className:"";const w=a.languageDetectRe.exec(h);if(w){const y=G(w[1]);return y||($e(_.replace("{}",w[1])),$e("Falling back to no-highlight mode for this block.",s)),y?w[1]:"no-highlight"}return h.split(/\s+/).find(y=>g(y)||G(y))}(s);if(g(w))return;if(we("before:highlightElement",{el:s,language:w}),s.dataset.highlighted)return void console.log("Element previously highlighted. To highlight again, first unset `dataset.highlighted`.",s);if(s.children.length>0&&(a.ignoreUnescapedHTML||(console.warn("One of your code blocks includes unescaped HTML. This is a potentially serious security risk."),console.warn("https://github.com/highlightjs/highlight.js/wiki/security"),console.warn("The element with unescaped HTML:"),console.warn(s)),a.throwUnescapedHTML))throw new _t("One of your code blocks includes unescaped HTML.",s.innerHTML);h=s;const y=h.textContent,v=w?F(y,{language:w,ignoreIllegals:!0}):Te(y);s.innerHTML=v.value,s.dataset.highlighted="yes",function vt(s,h,w){const y=h&&i[h]||w;s.classList.add("hljs"),s.classList.add(`language-${y}`)}(s,w,v.language),s.result={language:v.language,re:v.relevance,relevance:v.relevance},v.secondBest&&(s.secondBest={language:v.secondBest.language,relevance:v.secondBest.relevance}),we("after:highlightElement",{el:s,result:v,text:y})}let We=!1;function me(){"loading"!==document.readyState?document.querySelectorAll(a.cssSelector).forEach(Pe):We=!0}function G(s){return s=(s||"").toLowerCase(),n[s]||n[i[s]]}function Ve(s,{languageName:h}){"string"==typeof s&&(s=[s]),s.forEach(w=>{i[w.toLowerCase()]=h})}function Ke(s){const h=G(s);return h&&!h.disableAutodetect}function we(s,h){const w=s;f.forEach(function(y){y[w]&&y[w](h)})}typeof window<"u"&&window.addEventListener&&window.addEventListener("DOMContentLoaded",function Ot(){We&&me()},!1),Object.assign(t,{highlight:F,highlightAuto:Te,highlightAll:me,highlightElement:Pe,highlightBlock:function At(s){return Z("10.7.0","highlightBlock will be removed entirely in v12.0"),Z("10.7.0","Please use highlightElement now."),Pe(s)},configure:function Et(s){a=Ge(a,s)},initHighlighting:()=>{me(),Z("10.6.0","initHighlighting() deprecated.  Use highlightAll() now.")},initHighlightingOnLoad:function Mt(){me(),Z("10.6.0","initHighlightingOnLoad() deprecated.  Use highlightAll() now.")},registerLanguage:function Ct(s,h){let w=null;try{w=h(t)}catch(y){if(K("Language definition for '{}' could not be registered.".replace("{}",s)),!x)throw y;K(y),w=l}w.name||(w.name=s),n[s]=w,w.rawDefinition=h.bind(null,t),w.aliases&&Ve(w.aliases,{languageName:s})},unregisterLanguage:function Rt(s){delete n[s];for(const h of Object.keys(i))i[h]===s&&delete i[h]},listLanguages:function St(){return Object.keys(n)},getLanguage:G,registerAliases:Ve,autoDetection:Ke,inherit:Ge,addPlugin:function Pt(s){(function Tt(s){s["before:highlightBlock"]&&!s["before:highlightElement"]&&(s["before:highlightElement"]=h=>{s["before:highlightBlock"](Object.assign({block:h.el},h))}),s["after:highlightBlock"]&&!s["after:highlightElement"]&&(s["after:highlightElement"]=h=>{s["after:highlightBlock"](Object.assign({block:h.el},h))})})(s),f.push(s)},removePlugin:function Nt(s){const h=f.indexOf(s);-1!==h&&f.splice(h,1)}}),t.debugMode=function(){x=!1},t.safeMode=function(){x=!0},t.versionString="11.9.0",t.regex={concat:B,lookahead:ce,either:ie,optional:ve,anyNumberOfTimes:Fe};for(const s in fe)"object"==typeof fe[s]&&te(fe[s]);return Object.assign(t,fe),t},ee=ze({});ee.newInstance=()=>ze({}),Be.exports=ee,ee.HighlightJS=ee,ee.default=ee}}]);